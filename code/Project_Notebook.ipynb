{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the Gym Landscape: Analyzing Customer Reviews in Danish Facilities\n",
    "## Notebook code\n",
    "This notebook provides the code needed to reproduce the results presented in the report named \"Navigating the Gym Landscape: Analyzing Customer Reviews in Danish Facilities\" by the Data-Wild-West group. In case of doubts, consult the README file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "Customer reviews have become a major topic of research for brands of all industries, and without a doubt a significant driving force moving consumers’ decisions. This notebook provides a complete framework from data collection to data insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ginof\\OneDrive - ITU\\Documents\\GitHub\\data-wild-west\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# Google Maps API\n",
    "import googlemaps\n",
    "\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Custom util functions\n",
    "import sys; sys.path.append(\"./libraries/\")\n",
    "from utils import *\n",
    "\n",
    "# Classification models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Statistics\n",
    "from scipy.stats import tukey_hsd, f_oneway\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "import seaborn as sns\n",
    "\n",
    "# Maps\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reproducibility settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for experiments\n",
    "np.random.seed = 7\n",
    "\n",
    "# Relative Paths\n",
    "GOOGLE_API_TOKEN = \"./Google_API_key.txt\"\n",
    "RAW_DATA = \"../data/raw_data/\"\n",
    "PROCESSED_DATA = \"../data/processed_data/\"\n",
    "ANNOTATIONS_DATA = \"../annotations/\"\n",
    "\n",
    "# Some style settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set(font=\"Arial\")\n",
    "\n",
    "# Flags\n",
    "collect = False # Flag to collect data or load existent raw_data\n",
    "process = False # Flag to process data or load existent processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open(GOOGLE_API_TOKEN).readline()\n",
    "gmaps = googlemaps.Client(key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Methods\n",
    "The following section introduces the steps taken to collect and process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a list of query values that relate to the dataset. We are interested in getting mostly reviews (and some other metadata) on specific fitness facilities (i.e. popular chains) from main cities in Denmark. To do this, we will compute the query list as a combination of cities and fitness chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PureGym Copenhagen', 'PureGym Aalborg', 'PureGym Arhus', 'PureGym Odense', 'SATS Copenhagen', 'SATS Aalborg', 'SATS Arhus', 'SATS Odense', 'Vesterbronx Copenhagen', 'Vesterbronx Aalborg', 'Vesterbronx Arhus', 'Vesterbronx Odense']\n"
     ]
    }
   ],
   "source": [
    "# List of cities\n",
    "cities = ['Copenhagen', 'Aalborg', 'Arhus', 'Odense']\n",
    " \n",
    "# Popular fitness chains\n",
    "gyms = [\"PureGym\", \"SATS\", \"Vesterbronx\"]\n",
    "\n",
    "# Query list\n",
    "query_list = [g + \" \" + c for g in gyms for c in cities]\n",
    "\n",
    "print(query_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Google Maps API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google maps API takes a single query string to search for results (similar to the User Interface searchbox). Therefore, we combine popular fitness facilities with main Danish cities as our query keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses for all the queries from the API\n",
    "if collect:\n",
    "    # Get response for queries\n",
    "    dfs = []\n",
    "\n",
    "    # For each query in the query list\n",
    "    for query in query_list:  \n",
    "        # Get the response using our custom made querier\n",
    "        dfs.append(google_querier(gmaps, query))\n",
    "\n",
    "    google_reviews = pd.concat(dfs)\n",
    "\n",
    "    # Save to disk\n",
    "    google_reviews.to_csv(RAW_DATA + \"google_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    google_reviews = pd.read_csv(RAW_DATA + \"google_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (360, 9)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 360 entries, 0 to 359\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   place_id       360 non-null    object \n",
      " 1   type           360 non-null    object \n",
      " 2   name           360 non-null    object \n",
      " 3   lat            360 non-null    float64\n",
      " 4   lng            360 non-null    float64\n",
      " 5   author_name    360 non-null    object \n",
      " 6   rating         360 non-null    int64  \n",
      " 7   text           360 non-null    object \n",
      " 8   opening_hours  360 non-null    object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 25.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>author_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>opening_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>madi sharp</td>\n",
       "      <td>4</td>\n",
       "      <td>Sweet small gym, staff are kind when you see t...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Lewis Atkins</td>\n",
       "      <td>2</td>\n",
       "      <td>Just a very bad gym. Staff don’t really care, ...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Eric</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible facilities\\nbathrooms are gross, dirt...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Rune Perstrup</td>\n",
       "      <td>1</td>\n",
       "      <td>An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Mario Piazza</td>\n",
       "      <td>1</td>\n",
       "      <td>In a huge gym there is only one hair dryer and...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id                type     name        lat  \\\n",
       "0  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "1  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "2  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "3  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "4  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "\n",
       "        lng    author_name  rating  \\\n",
       "0  12.54739     madi sharp       4   \n",
       "1  12.54739   Lewis Atkins       2   \n",
       "2  12.54739           Eric       1   \n",
       "3  12.54739  Rune Perstrup       1   \n",
       "4  12.54739   Mario Piazza       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Sweet small gym, staff are kind when you see t...   \n",
       "1  Just a very bad gym. Staff don’t really care, ...   \n",
       "2  terrible facilities\\nbathrooms are gross, dirt...   \n",
       "3  An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...   \n",
       "4  In a huge gym there is only one hair dryer and...   \n",
       "\n",
       "                                       opening_hours  \n",
       "0  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "1  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "2  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "3  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "4  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(google_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Trustpilot WebScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trustpilot is a Danish consumer review website very popular in Denmark. It is publicly available and easy to access, but it does not provide any API integration. Therefore, we use a simple webcrawler to extract the reviews of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    dfs = []\n",
    "\n",
    "    # Reuse the gyms\n",
    "    for g in gyms:\n",
    "        df = trustpilot_crawler(key=g, verbose=False)\n",
    "\n",
    "        # Append the facility DF to main df\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Join all DFs\n",
    "    trustpilot_reviews = pd.concat(dfs)\n",
    "\n",
    "    # Save to disk\n",
    "    trustpilot_reviews.to_csv(RAW_DATA + \"trustpilot_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    trustpilot_reviews = pd.read_csv(RAW_DATA + \"trustpilot_reviews.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (2802, 7)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2802 entries, 0 to 2801\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   datetime    2802 non-null   object\n",
      " 1   name        2802 non-null   object\n",
      " 2   rating      2802 non-null   int64 \n",
      " 3   title       2802 non-null   object\n",
      " 4   review      2802 non-null   object\n",
      " 5   event_time  2802 non-null   object\n",
      " 6   enterprise  2802 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 153.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>event_time</th>\n",
       "      <th>enterprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-13T14:03:40.000Z</td>\n",
       "      <td>Jan Winther</td>\n",
       "      <td>4</td>\n",
       "      <td>Godt fitness-center</td>\n",
       "      <td>Gennemgående er jeg godt tilfreds med mit fitn...</td>\n",
       "      <td>13. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-14T13:07:20.000Z</td>\n",
       "      <td>Tina Holst</td>\n",
       "      <td>5</td>\n",
       "      <td>Syntes altid det er dejligt at komme i…</td>\n",
       "      <td>Syntes altid det er dejligt at komme i centret...</td>\n",
       "      <td>14. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-13T09:22:36.000Z</td>\n",
       "      <td>Pfændtner</td>\n",
       "      <td>5</td>\n",
       "      <td>Jeg har gået i Fitness centeret i 22år…</td>\n",
       "      <td>Jeg har gået i Fitness centeret i 22år og efte...</td>\n",
       "      <td>12. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-13T17:18:33.000Z</td>\n",
       "      <td>Gitte</td>\n",
       "      <td>5</td>\n",
       "      <td>Puregym Ikast</td>\n",
       "      <td>Puregym Ikast er et fantastisk center. Man føl...</td>\n",
       "      <td>13. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-13T10:01:35.000Z</td>\n",
       "      <td>GITTE MIKKELSEN</td>\n",
       "      <td>2</td>\n",
       "      <td>Der mangler Stram op hold</td>\n",
       "      <td>Der mangler Stram op hold (eller ligende fx Pu...</td>\n",
       "      <td>11. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime             name  rating  \\\n",
       "0  2023-11-13T14:03:40.000Z      Jan Winther       4   \n",
       "1  2023-11-14T13:07:20.000Z       Tina Holst       5   \n",
       "2  2023-11-13T09:22:36.000Z        Pfændtner       5   \n",
       "3  2023-11-13T17:18:33.000Z            Gitte       5   \n",
       "4  2023-11-13T10:01:35.000Z  GITTE MIKKELSEN       2   \n",
       "\n",
       "                                     title  \\\n",
       "0                      Godt fitness-center   \n",
       "1  Syntes altid det er dejligt at komme i…   \n",
       "2  Jeg har gået i Fitness centeret i 22år…   \n",
       "3                            Puregym Ikast   \n",
       "4                Der mangler Stram op hold   \n",
       "\n",
       "                                              review         event_time  \\\n",
       "0  Gennemgående er jeg godt tilfreds med mit fitn...  13. november 2023   \n",
       "1  Syntes altid det er dejligt at komme i centret...  14. november 2023   \n",
       "2  Jeg har gået i Fitness centeret i 22år og efte...  12. november 2023   \n",
       "3  Puregym Ikast er et fantastisk center. Man føl...  13. november 2023   \n",
       "4  Der mangler Stram op hold (eller ligende fx Pu...  11. november 2023   \n",
       "\n",
       "  enterprise  \n",
       "0    PureGym  \n",
       "1    PureGym  \n",
       "2    PureGym  \n",
       "3    PureGym  \n",
       "4    PureGym  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(trustpilot_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Københavns Kommune Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Københavns Kommune website provides an extensive list of training facilities, both indoors and outdoors. Since this is a dynamic site built on JavaScript, the traditional webcrawler approach is not suitable, and thus we will use an approach that simulates human-like interactions using Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "\n",
    "    # Create crawler instance\n",
    "    kbh_scraper = KBHFacilitiesWebScraper()\n",
    "    # Get dataframe with entries\n",
    "    kbh_facilities = kbh_scraper.get()\n",
    "\n",
    "    # Save to disk\n",
    "    kbh_facilities.to_csv(RAW_DATA + \"kbh_facilities.csv\", index=False, encoding=\"utf-16\") # Since some Danish characters don't map to utf-8, we use utf-16\n",
    "    \n",
    "\n",
    "else:\n",
    "    kbh_facilities = pd.read_csv(RAW_DATA + \"kbh_facilities.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (515, 9)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515 entries, 0 to 514\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  515 non-null    int64 \n",
      " 1   type        515 non-null    object\n",
      " 2   activity    515 non-null    object\n",
      " 3   location    508 non-null    object\n",
      " 4   website     514 non-null    object\n",
      " 5   gender      515 non-null    object\n",
      " 6   age         515 non-null    object\n",
      " 7   special     106 non-null    object\n",
      " 8   address     499 non-null    object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 36.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>special</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gym</td>\n",
       "      <td>Styrke- og grundtræning</td>\n",
       "      <td>SOS Motion</td>\n",
       "      <td>http://www.sosmotion.dk/</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sundhedshus Østerbro, Randersgade 60, 4 sal, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>gym</td>\n",
       "      <td>Nærgymnastik</td>\n",
       "      <td>LOFskolen</td>\n",
       "      <td>https://lofskolen.dk/kurser/motion-og-sundhed/...</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>Målrettet personer der har brug for træning me...</td>\n",
       "      <td>Østerbrogade 240, 2100 København Ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ball_sports</td>\n",
       "      <td>Floorball for kvinder 65+ år</td>\n",
       "      <td>BK Skjold</td>\n",
       "      <td>https://www.bkskjold.dk/klub/boldklubben-skjol...</td>\n",
       "      <td>women</td>\n",
       "      <td>seniors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nørrebrogade 208, 2200 Kbh. N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>gym</td>\n",
       "      <td>Fitness og styrketræning</td>\n",
       "      <td>Nabo Østerbro</td>\n",
       "      <td>https://www.naboosterbro.dk/styrketr%c3%a6ning...</td>\n",
       "      <td>both</td>\n",
       "      <td>seniors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nyborggade 9, 2100 Kbh Ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>gym</td>\n",
       "      <td>KOL-/hjerte træningshold</td>\n",
       "      <td>FOF</td>\n",
       "      <td>https://www.fof.dk/da/kbh/kurser/samarbejde-me...</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vesterbrogade 121, 1620 Kbh. V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         type                      activity       location  \\\n",
       "0           0          gym       Styrke- og grundtræning     SOS Motion   \n",
       "1           3          gym                  Nærgymnastik      LOFskolen   \n",
       "2           4  ball_sports  Floorball for kvinder 65+ år      BK Skjold   \n",
       "3           5          gym      Fitness og styrketræning  Nabo Østerbro   \n",
       "4           6          gym      KOL-/hjerte træningshold            FOF   \n",
       "\n",
       "                                             website gender      age  \\\n",
       "0                           http://www.sosmotion.dk/   both      all   \n",
       "1  https://lofskolen.dk/kurser/motion-og-sundhed/...   both      all   \n",
       "2  https://www.bkskjold.dk/klub/boldklubben-skjol...  women  seniors   \n",
       "3  https://www.naboosterbro.dk/styrketr%c3%a6ning...   both  seniors   \n",
       "4  https://www.fof.dk/da/kbh/kurser/samarbejde-me...   both      all   \n",
       "\n",
       "                                             special  \\\n",
       "0                                                NaN   \n",
       "1  Målrettet personer der har brug for træning me...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             address  \n",
       "0  Sundhedshus Østerbro, Randersgade 60, 4 sal, 2...  \n",
       "1                 Østerbrogade 240, 2100 København Ø  \n",
       "2                      Nørrebrogade 208, 2200 Kbh. N  \n",
       "3                           Nyborggade 9, 2100 Kbh Ø  \n",
       "4                     Vesterbrogade 121, 1620 Kbh. V  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(kbh_facilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3.1 Lookup reviews for KBH Facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this dataset only contains addresses, but not geolocation (latitude and longitude) or reviews for the places. We then try to collect that missing data from the Google Maps API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    # Use custom function to iterate through the facilities and retrieve coordinates and reviews for the places.\n",
    "    kbh_facilities_reviews = review_finder(gmaps, kbh_facilities)\n",
    "\n",
    "    # Save to disk\n",
    "    kbh_facilities_reviews.to_csv(RAW_DATA + \"kbh_facilities.csv\", index=False, encoding=\"utf-16\") # Since some Danish characters don't map to utf-8, we use utf-16\n",
    "\n",
    "else:\n",
    "    kbh_facilities_reviews = pd.read_csv(RAW_DATA + \"kbh_facilities_reviews.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (1841, 13)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1841 entries, 0 to 1840\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   type      1841 non-null   object \n",
      " 1   activity  1841 non-null   object \n",
      " 2   location  1756 non-null   object \n",
      " 3   website   1477 non-null   object \n",
      " 4   gender    1841 non-null   object \n",
      " 5   age       1841 non-null   object \n",
      " 6   special   250 non-null    object \n",
      " 7   address   1481 non-null   object \n",
      " 8   lat       1460 non-null   float64\n",
      " 9   lng       1460 non-null   float64\n",
      " 10  author    1841 non-null   object \n",
      " 11  review    1841 non-null   object \n",
      " 12  rating    1841 non-null   float64\n",
      "dtypes: float64(3), object(10)\n",
      "memory usage: 187.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>special</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>author</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Ximena Ramos</td>\n",
       "      <td>This was the first time that we ordered this f...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>David Olafsson</td>\n",
       "      <td>My wife and I have been coming here with our d...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Rune Madsen</td>\n",
       "      <td>Amazing new Chinese food in the area. We had M...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Richard Grieg Higginson</td>\n",
       "      <td>Nice food and staff</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Hjalte Christiansen</td>\n",
       "      <td>We ordered lunch takeaway. But they had forgot...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type           activity location website gender  age special  \\\n",
       "0  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "1  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "2  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "3  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "4  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "\n",
       "                     address        lat       lng                   author  \\\n",
       "0  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313             Ximena Ramos   \n",
       "1  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313           David Olafsson   \n",
       "2  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313              Rune Madsen   \n",
       "3  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313  Richard Grieg Higginson   \n",
       "4  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313      Hjalte Christiansen   \n",
       "\n",
       "                                              review  rating  \n",
       "0  This was the first time that we ordered this f...     3.0  \n",
       "1  My wife and I have been coming here with our d...     5.0  \n",
       "2  Amazing new Chinese food in the area. We had M...     5.0  \n",
       "3                                Nice food and staff     4.0  \n",
       "4  We ordered lunch takeaway. But they had forgot...     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(kbh_facilities_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in constructing a dataset that includes the enterprise, rating and review text, so we need to ensure those attributes are accesible across the different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract enterprise for Google reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract enterprise for Google reviews\n",
    "_enterprises_ = []\n",
    "# Look at each row\n",
    "for ix, row in google_reviews.iterrows():\n",
    "    # If not one of the main chains, default to \"OTHER\"\n",
    "    result = \"OTHER\"\n",
    "    # Search for the enterprise in either \"type\" or \"name\" columns\n",
    "    for enterprise in gyms:\n",
    "        if (enterprise.lower() in row[\"type\"].lower()) or (enterprise.lower() in row[\"name\"].lower()):\n",
    "            result = enterprise\n",
    "            break\n",
    "    _enterprises_.append(result)\n",
    "\n",
    "google_reviews[\"enterprise\"] = _enterprises_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract enterprise for KBH Facilities reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # Extract enterprise for Google reviews\n",
    "    _enterprises_ = []\n",
    "\n",
    "    # Since some attributes are NAN, we replace them by the string \"nan\"\n",
    "    _ = kbh_facilities_reviews.fillna(\"nan\")\n",
    "\n",
    "    # Look at each row\n",
    "    for ix, row in _.iterrows():\n",
    "        # If not one of the main chains, default to \"OTHER\"\n",
    "        result = \"OTHER\"\n",
    "        # Search for the enterprise in either \"type\" or \"name\" columns\n",
    "        for enterprise in gyms:\n",
    "            _ = kbh_facilities_reviews.fillna(\"nan\")\n",
    "            if (enterprise.lower() in row[\"type\"].lower()) or (enterprise.lower() in row[\"location\"].lower()):\n",
    "                result = enterprise\n",
    "                break\n",
    "        _enterprises_.append(result)\n",
    "\n",
    "    # Add the enterprise to the dataset\n",
    "    kbh_facilities_reviews[\"enterprise\"] = _enterprises_\n",
    "\n",
    "    # Save the results to disk\n",
    "    kbh_facilities_reviews.to_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    kbh_facilities_reviews = pd.read_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Translation of Danish reviews\n",
    "Our Trustpilot dataset contains content in both English and Danish languages. We want to translate everything to english, to work with a monolingual dataset.\n",
    "To accomplish the translation task, we use a translation model from Hugging-Face: Helsinki-NLP/opus-mt-da-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # First, remove all emojis to facilitate translation\n",
    "    trustpilot_reviews[\"review\"] = trustpilot_reviews[\"review\"].apply(lambda x: remove_emojis(x))\n",
    "\n",
    "    # Use custom function to translate the Danish reviews\n",
    "    trustpilot_reviews = translate(df = trustpilot_reviews, text_colname = \"review\", translation_colname=\"translated_review\")\n",
    "else:\n",
    "    trustpilot_reviews = pd.read_csv(PROCESSED_DATA + \"trustpilot_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Translation Assesment\n",
    "We assess the quality of the model's translation by computing the WER (Word error rate) metric against human translators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The WER for the translations sample is 0.388\n"
     ]
    }
   ],
   "source": [
    "# Translations folder\n",
    "filepath = \"../translations/human_translations.csv\"\n",
    "\n",
    "# We load the human translations and strip the emojis\n",
    "human = pd.read_csv(filepath)\n",
    "human[\"review\"] = human.review.apply(lambda x: remove_emojis(x))\n",
    "human.rename(columns={\"review\": \"text\", \"translation\": \"human\"}, inplace=True)\n",
    "\n",
    "# We extact the model translations\n",
    "machine = trustpilot_reviews[[\"review\", \"translated_review\"]]\n",
    "machine.rename(columns={\"review\": \"text\", \"translated_review\": \"machine\"}, inplace=True)\n",
    "\n",
    "# We match the translations to their human counterpart\n",
    "translations = human.merge(machine, on=\"text\", how=\"inner\")\n",
    "\n",
    "# We pass the text, human and machine translations to our custom WER class\n",
    "WER = WER(translations.text, translations.human, translations.machine)\n",
    "\n",
    "# We use our custom function to compute the average Word error rate for the whole sample\n",
    "print(f\"The WER for the translations sample is {WER.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the top best and worst WER instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Human</th>\n",
       "      <th>Machine</th>\n",
       "      <th>WER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Den dårligste Santa jeg har set alt den styrke...</td>\n",
       "      <td>The worst sats I have seen on Nørrebro</td>\n",
       "      <td>The worst Santa I've seen all the strength you...</td>\n",
       "      <td>1.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jeg syntes dør er et godt trænings center jeg ...</td>\n",
       "      <td>I think this is a good gym, however there shou...</td>\n",
       "      <td>I think door is a good training center. I just...</td>\n",
       "      <td>0.633136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Udemærket træningscenter med stort set hvad ma...</td>\n",
       "      <td>Fine training center with basically everything...</td>\n",
       "      <td>Excellent gym with practically what to use. To...</td>\n",
       "      <td>0.579882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>God stemning i Sats  og et utal af træningsmul...</td>\n",
       "      <td>Good vibes in Sats and countless ways of worki...</td>\n",
       "      <td>Good atmosphere in Sats and numerous training ...</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(anmeldelsen er skrevet efter 8 besøg i center...</td>\n",
       "      <td>The review is written after 8 visits to the ce...</td>\n",
       "      <td>(the review is written after 8 visits to the c...</td>\n",
       "      <td>0.528662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "21  Den dårligste Santa jeg har set alt den styrke...   \n",
       "7   Jeg syntes dør er et godt trænings center jeg ...   \n",
       "28  Udemærket træningscenter med stort set hvad ma...   \n",
       "41  God stemning i Sats  og et utal af træningsmul...   \n",
       "5   (anmeldelsen er skrevet efter 8 besøg i center...   \n",
       "\n",
       "                                                Human  \\\n",
       "21             The worst sats I have seen on Nørrebro   \n",
       "7   I think this is a good gym, however there shou...   \n",
       "28  Fine training center with basically everything...   \n",
       "41  Good vibes in Sats and countless ways of worki...   \n",
       "5   The review is written after 8 visits to the ce...   \n",
       "\n",
       "                                              Machine       WER  \n",
       "21  The worst Santa I've seen all the strength you...  1.078947  \n",
       "7   I think door is a good training center. I just...  0.633136  \n",
       "28  Excellent gym with practically what to use. To...  0.579882  \n",
       "41  Good atmosphere in Sats and numerous training ...  0.535714  \n",
       "5   (the review is written after 8 visits to the c...  0.528662  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Human</th>\n",
       "      <th>Machine</th>\n",
       "      <th>WER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Forfærdlig forløb hos sats, Sats sender min ti...</td>\n",
       "      <td>Horrible course at sats, Sets sent mine to deb...</td>\n",
       "      <td>Terrible course with the rate, Sats sends mine...</td>\n",
       "      <td>0.234286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skal betale for en ekstra måned selvom jeg ops...</td>\n",
       "      <td>I had to pay for an extra month even though I ...</td>\n",
       "      <td>Must pay for an extra month even though I quit...</td>\n",
       "      <td>0.197970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Det er altid en stor fornøjelse at træne på Cl...</td>\n",
       "      <td>It is always a great pleassure to train on Cla...</td>\n",
       "      <td>It's always a great pleasure to train on Clara...</td>\n",
       "      <td>0.192000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Jeg er ikke medlem, jeg var på vej til at meld...</td>\n",
       "      <td>I'm not a member, I was about to become one at...</td>\n",
       "      <td>I'm not a member, I was about to sign up today...</td>\n",
       "      <td>0.187192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SATS Glostrup's sauna er altid i stykker, 2-3 ...</td>\n",
       "      <td>Sats Glostrup's sauna is always broken, 2-3 ti...</td>\n",
       "      <td>SATS Glostrup's sauna is always broken, 2-3 ti...</td>\n",
       "      <td>0.170732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "15  Forfærdlig forløb hos sats, Sats sender min ti...   \n",
       "16  Skal betale for en ekstra måned selvom jeg ops...   \n",
       "19  Det er altid en stor fornøjelse at træne på Cl...   \n",
       "24  Jeg er ikke medlem, jeg var på vej til at meld...   \n",
       "40  SATS Glostrup's sauna er altid i stykker, 2-3 ...   \n",
       "\n",
       "                                                Human  \\\n",
       "15  Horrible course at sats, Sets sent mine to deb...   \n",
       "16  I had to pay for an extra month even though I ...   \n",
       "19  It is always a great pleassure to train on Cla...   \n",
       "24  I'm not a member, I was about to become one at...   \n",
       "40  Sats Glostrup's sauna is always broken, 2-3 ti...   \n",
       "\n",
       "                                              Machine       WER  \n",
       "15  Terrible course with the rate, Sats sends mine...  0.234286  \n",
       "16  Must pay for an extra month even though I quit...  0.197970  \n",
       "19  It's always a great pleasure to train on Clara...  0.192000  \n",
       "24  I'm not a member, I was about to sign up today...  0.187192  \n",
       "40  SATS Glostrup's sauna is always broken, 2-3 ti...  0.170732  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(WER.ranking().head())\n",
    "display(WER.ranking().tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the attributes to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match across datasets\n",
    "google_reviews = google_reviews.rename(columns={\"author_name\": \"author\", \"text\": \"review\"})\n",
    "trustpilot_reviews = trustpilot_reviews.rename(columns={\"name\": \"author\", \"translated_reviews\": \"review\"})\n",
    "\n",
    "# Columns to keep\n",
    "cols = ['enterprise', 'author', 'rating', 'review']\n",
    "\n",
    "# Keep useful columns\n",
    "google_reviews = google_reviews[cols]\n",
    "google_reviews[\"platform\"] = \"Google\"\n",
    "trustpilot_reviews = trustpilot_reviews[cols]\n",
    "trustpilot_reviews[\"platform\"] = \"Trustpilot\"\n",
    "kbh_facilities_reviews = kbh_facilities_reviews[cols]\n",
    "kbh_facilities_reviews[\"platform\"] = \"Google\"\n",
    "\n",
    "# Merge all reviews\n",
    "reviews = pd.concat([google_reviews, trustpilot_reviews, kbh_facilities_reviews]).reset_index(drop=True)\n",
    "\n",
    "# Drop duplicates\n",
    "reviews = reviews.drop_duplicates(ignore_index=True, keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (3586, 5)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3586 entries, 0 to 3585\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   enterprise  3586 non-null   object \n",
      " 1   author      3586 non-null   object \n",
      " 2   rating      3586 non-null   float64\n",
      " 3   review      3583 non-null   object \n",
      " 4   platform    3586 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 140.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enterprise</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>madi sharp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sweet small gym, staff are kind when you see t...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Lewis Atkins</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Just a very bad gym. Staff don’t really care, ...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Eric</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible facilities\\nbathrooms are gross, dirt...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Rune Perstrup</td>\n",
       "      <td>1.0</td>\n",
       "      <td>An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Mario Piazza</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In a huge gym there is only one hair dryer and...</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  enterprise         author  rating  \\\n",
       "0    PureGym     madi sharp     4.0   \n",
       "1    PureGym   Lewis Atkins     2.0   \n",
       "2    PureGym           Eric     1.0   \n",
       "3    PureGym  Rune Perstrup     1.0   \n",
       "4    PureGym   Mario Piazza     1.0   \n",
       "\n",
       "                                              review platform  \n",
       "0  Sweet small gym, staff are kind when you see t...   Google  \n",
       "1  Just a very bad gym. Staff don’t really care, ...   Google  \n",
       "2  terrible facilities\\nbathrooms are gross, dirt...   Google  \n",
       "3  An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...   Google  \n",
       "4  In a huge gym there is only one hair dryer and...   Google  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to discern specific elements or topics within the reviews to enhance the classification of customer satisfaction. The classification comprised two dimensions: sentiment and object/topic. Sentiment analysis utilized three labels— “Positive,” “Negative,” and “Neutral.” The latter allowed for the identification of reviews expressing both sentiments toward a single object or exhibiting a subtle sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation distribution\n",
    "To avoid introducing bias to the task, we remove all columns except for the text to annotate, and we randomly distribute the samples across annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join both datasets\n",
    "review_text = pd.DataFrame(reviews[\"review\"])\n",
    "\n",
    "# Shuffle reviews\n",
    "review_text = review_text.sample(frac=1)\n",
    "\n",
    "# Give unique ID to reviews\n",
    "review_text[\"ID\"] = np.arange(1, len(reviews)+1)\n",
    "\n",
    "# Drop the index\n",
    "review_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Size of sample annotated by all annotators\n",
    "size = 100\n",
    "\n",
    "# Keep a list of not assigned IDs\n",
    "remaining_ids = list(review_text.ID)\n",
    "\n",
    "# Randomly select some IDs\n",
    "common_ids =np.random.choice(remaining_ids, size=size, replace=False)\n",
    "# Assign those instances to \"all\" annotators\n",
    "review_text.loc[review_text.ID.isin(common_ids), \"annotator\"] = \"all\"\n",
    "# Remove the selected IDs from the remaining not assigned IDs\n",
    "remaining_ids = [x for x in remaining_ids if x not in common_ids]\n",
    "\n",
    "# List of annotators\n",
    "annotators = [\"Bogdan\", \"Chrisanna\", \"Christian\", \"Gino\", \"Veron\"]\n",
    "\n",
    "# Size of the samples\n",
    "size = 202\n",
    "# Assign to each annotator\n",
    "for a in annotators:\n",
    "    # Randomly select some IDs\n",
    "    selected_ids = np.random.choice(remaining_ids, size=size, replace=False)\n",
    "    # Assign those instances to the specific annotator\n",
    "    review_text.loc[review_text.ID.isin(selected_ids), \"annotator\"] = a\n",
    "    # Remove the selected IDs from the remaining not assigned IDs\n",
    "    remaining_ids = [x for x in remaining_ids if x not in selected_ids]\n",
    "\n",
    "# Show number of instances per annotator\n",
    "display(review_text.groupby(\"annotator\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now distribute the samples to annotate across annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # For each annotator, create a file\n",
    "    for a in annotators:\n",
    "        # Get the annotations for the specific annotator\n",
    "        annotators_sample = reviews.loc[(reviews.annotator == a) | (reviews.annotator == \"all\"), [\"ID\", \"text\"]]\n",
    "        annotators_sample.to_csv(ANNOTATIONS_DATA + f\"annotators_samples/{a}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the annotation responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for individual annotation responses datasets\n",
    "dfs = []\n",
    "\n",
    "# Look at the JSON files, parse and join\n",
    "for file in os.listdir(ANNOTATIONS_DATA + \"annotators_results\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        # Use our custom function to parse the response file\n",
    "        df = parse_label_studio_file(ANNOTATIONS_DATA + \"annotators_results/\" + file)\n",
    "        # Append to the container\n",
    "        dfs.append(df)\n",
    "\n",
    "# Join all files\n",
    "annotations = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "print(f\"A total of {annotations.shape[0]} are now joined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Calculate IAA\n",
    "To assess the reliability of the annotations we calculate Fleiss' kappa inter-annotator agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The categories are in the columns (except the first two: \"ID\" and \"text\")\n",
    "categories = annotations.columns[2:]\n",
    "# The possible labels are 1.0 (Positive), 0.0 (Neutral), -1.0 (Negative) or NAN (if no sentiment)\n",
    "labels = [1.0, 0.0, -1.0, np.nan]\n",
    "# Select the common annotations for IAA\n",
    "common_annotations = annotations.groupby(\"ID\").filter(lambda x: len(x) == 5)\n",
    "\n",
    "IAA = fleiss_kappa(common_annotations, categories, labels=labels)\n",
    "\n",
    "print(f\"The Fleiss Kappa for IAA is {IAA:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at each category separetely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in categories:\n",
    "\n",
    "    IAA = fleiss_kappa(common_annotations, [cat], labels=labels)\n",
    "\n",
    "    print(f\"The Fleiss Kappa for IAA for the {cat} category is {IAA:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide on a golden label\n",
    "We now decide on a golden label for the common annotations. We will use majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the golden label by majority voting\n",
    "common_annotations = common_annotations.groupby(\"ID\").agg(lambda x: pd.Series.mode(x, dropna=False)[0]).reset_index()\n",
    "\n",
    "# Join to individual annotations\n",
    "annotations = pd.concat([common_annotations, annotations[~annotations.ID.isin(common_annotations.ID)]])\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Basic Data Exploration\n",
    "\n",
    "The purpose of this section is to conduct some initial exploration into the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLACEHOLDER FOR GRAPH FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Auto-labeller classifier\n",
    "Train a classifier model using Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the annotations\n",
    "df = annotations.copy()\n",
    "# Convert the labels into text\n",
    "df.iloc[:,2:] = df.iloc[:,2:].applymap(lambda x: num_to_sent(x))\n",
    "# Correct spelling mistakes\n",
    "clean_text = grammar_corrector(df[\"text\"])\n",
    "df[\"text\"] = clean_text\n",
    "# Lemmatize\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: lemmatize_with_postag(x))\n",
    "\n",
    "# Use vectorizer to encode text as features. TfidfVectorizer takes care of lowering and tokenizing the text\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", strip_accents=\"unicode\")\n",
    "X_tfidf = vectorizer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring_metrics = ['precision_macro', 'recall_macro', 'f1_macro', \"accuracy\"]\n",
    "\n",
    "# Evaluate category-wise\n",
    "for cat in categories:\n",
    "    print(cat)\n",
    "    # Perform cross-validation\n",
    "    scores = cross_validate(classifier, X_tfidf, df[cat], cv=cv, scoring=scoring_metrics, return_train_score=False, error_score=\"raise\")\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.loc['mean'] = scores.mean()\n",
    "    scores = scores.round(decimals=2)\n",
    "    display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and use the vectorizer to transform text to features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', strip_accents=\"unicode\")\n",
    "# We can't predict on missing text reviews\n",
    "reviews_w_NA = reviews[~reviews.review.isna()]\n",
    "reviews_w_NA[\"review\"] = reviews_w_NA[\"review\"].apply(lambda x: lemmatize_with_postag(x))\n",
    "X_tfidf = vectorizer.fit_transform(reviews_w_NA.review)\n",
    "\n",
    "# Choose your classifier\n",
    "for cat in categories:\n",
    "    # Train the classifier for a given category\n",
    "    classifier = MultinomialNB()\n",
    "    X_train = vectorizer.transform(df.text)\n",
    "    y_train = df[cat]\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on all instances of the reviews\n",
    "    y_pred = classifier.predict(X_tfidf)\n",
    "    reviews_w_NA[cat] = y_pred\n",
    "\n",
    "# Look at the final results\n",
    "reviews = pd.concat([reviews_w_NA, reviews[reviews.review.isna()]])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Visualizing the facilities with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the starting point for the map\n",
    "lat = 56\n",
    "lng = 9\n",
    "\n",
    "denmark_map = folium.Map(location=[lat,lng], zoom_start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations_google = pd.read_csv(RAW_DATA + \"google_reviews.csv\") \n",
    "geolocations_kbh = pd.read_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the location column is entirely null if so group by address instead\n",
    "if geolocations_kbh['location'].isnull().all():\n",
    "    kbh_grouping_field = 'address'\n",
    "else:\n",
    "    kbh_grouping_field = 'location'\n",
    "\n",
    "# group and aggregate kbh_facilities_reviews\n",
    "kbh_grouped_data = geolocations_kbh.groupby(kbh_grouping_field).agg({\n",
    "    'lat': 'first', 'lng': 'first', 'activity': 'first', \n",
    "    'type': 'first', 'rating': 'mean'}).reset_index()\n",
    "kbh_grouped_data['rating'] = kbh_grouped_data['rating'].round(1)\n",
    "\n",
    "# group and aggregate google_reviews\n",
    "google_grouped_data = geolocations_google.groupby(['lat', 'lng']).agg({\n",
    "    'type': 'first', 'rating': 'mean'}).reset_index()\n",
    "google_grouped_data['rating'] = google_grouped_data['rating'].round(1)\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(denmark_map)\n",
    "\n",
    "add_kbh_markers(kbh_grouped_data, marker_cluster)\n",
    "add_google_markers(google_grouped_data, marker_cluster)\n",
    "\n",
    "denmark_map.add_child(marker_cluster)\n",
    "# denmark_map.save('../visualizations/denmark_map.html')\n",
    "denmark_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Statistical Analysis\n",
    "Is there a statistically significant difference in the ratings from the main fitness brands in Denmark's main cities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of rating average per brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the ratings per gym\n",
    "ratings = []\n",
    "labels = []\n",
    "\n",
    "for gym in reviews.enterprise.unique():\n",
    "    labels.append(gym)\n",
    "    ratings.append(list(reviews.loc[reviews.enterprise == gym, \"rating\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of ratings\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.boxplot(ratings, palette=\"deep\", color=\".8\", linewidth=.75)\n",
    "ax.set_xticklabels(labels,fontsize=14) \n",
    "ax.set_ylabel(\"Rating\", fontsize=14) \n",
    "\n",
    "sns.despine(offset=10, trim=True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between brands: ANOVA Test and Tukey's HSD\n",
    "How significant are these differences in mean rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# ANOVA one way test\n",
    "stat, p_value = f_oneway(*ratings)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"With a significance level of {alpha}, we can reject the null hypothesis (P-value = {p_value:.3f})\")\n",
    "else:\n",
    "    print(f\"With a significance level of {alpha}, we cannot reject the null hypothesis (P-value = {p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the ANOVA test allows to reject the null hypothesis of equal means, we can perform a Tukey's HSD test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < alpha:\n",
    "    print([\" | \".join(f\"{i}: {l}\" for i, l in enumerate(labels))])\n",
    "    res = tukey_hsd(*ratings)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Platform effect on review ratings: Mixed Effect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model = sm.MixedLM.from_formula(\"rating ~ platform\", groups=\"enterprise\", data=data)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
