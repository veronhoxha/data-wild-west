{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Meaningful title >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Maps API\n",
    "import googlemaps\n",
    "\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Custom util functions\n",
    "import sys; sys.path.append(\"./libraries/\")\n",
    "from utils import *\n",
    "\n",
    "# Classification models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Maps\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reproducibility settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "np.random.seed = 7\n",
    "\n",
    "# Relative Paths\n",
    "RAW_DATA = \"../data/raw_data/\"\n",
    "PROCESSED_DATA = \"../data/processed_data/\"\n",
    "ANNOTATIONS_DATA = \"../annotations/\"\n",
    "\n",
    "# Flags\n",
    "collect = False # Flag to collect data or load existent raw_data\n",
    "process = False # Flag to process data or load existent processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open(\"./Google_API_key.txt\").readline()\n",
    "gmaps = googlemaps.Client(key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a list of query values that relate to the dataset. We are interested in getting mostly reviews (and some other metadata) on specific fitness facilities (i.e. popular chains) from main cities in Denmark. To do this, we will compute the query list as a combination of cities and fitness chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PureGym Copenhagen', 'PureGym Aalborg', 'PureGym Arhus', 'PureGym Odense', 'SATS Copenhagen', 'SATS Aalborg', 'SATS Arhus', 'SATS Odense', 'Vesterbronx Copenhagen', 'Vesterbronx Aalborg', 'Vesterbronx Arhus', 'Vesterbronx Odense']\n"
     ]
    }
   ],
   "source": [
    "# List of cities\n",
    "cities = ['Copenhagen', 'Aalborg', 'Arhus', 'Odense']\n",
    " \n",
    "# Popular fitness chains\n",
    "gyms = [\"PureGym\", \"SATS\", \"Vesterbronx\"]\n",
    "\n",
    "# Query list\n",
    "query_list = [g + \" \" + c for g in gyms for c in cities]\n",
    "\n",
    "print(query_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Google Maps API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google maps API takes a single query string to search for results (similar to the User Interface searchbox). Therefore, we combine popular fitness facilities with main Danish cities as our query keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Reviews\n",
    "We start by getting the reviews for our query list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get responses for all the queries from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    # Get response for queries\n",
    "    dfs = []\n",
    "\n",
    "    # For each query in the query list\n",
    "    for query in query_list:  \n",
    "        # Get the response using our custom made querier\n",
    "        dfs.append(google_querier(gmaps, query))\n",
    "\n",
    "    google_reviews = pd.concat(dfs)\n",
    "\n",
    "    # Save to disk\n",
    "    google_reviews.to_csv(RAW_DATA + \"google_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    google_reviews = pd.read_csv(RAW_DATA + \"google_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_dataframe_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m check_dataframe_results(google_reviews)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_dataframe_results' is not defined"
     ]
    }
   ],
   "source": [
    "check_dataframe_results(google_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Nearby Transportation\n",
    "We are interested in collecting the nearby transportation to the fitness centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "\n",
    "    # Radius of search in meters\n",
    "    radius = 500\n",
    "\n",
    "    # Transportation type key (similar to what one would input in Google Maps search box)\n",
    "    transportation_type = ['bus_station', 'train_station', 'transit_station'] # Avaliable transportation: only bus station, train station and transit station (which includes metro)\n",
    "\n",
    "    # Container\n",
    "    nearby_transportation = []\n",
    "\n",
    "    # We iterate through all our fitness centers, and retrieve nearby transportations\n",
    "    for ix, row in google_reviews.iterrows():\n",
    "        # Extract info from fitness center\n",
    "        place_id = row.place_id\n",
    "        location = {\"lat\": row.lat, \"lng\": row.lng}\n",
    "        # Look at nearby transportation\n",
    "        df = google_nearby(gmaps, place_id = place_id, keys = transportation_type, location = location, radius = radius)\n",
    "        # Append results\n",
    "        nearby_transportation.append(df)\n",
    "\n",
    "    # Join all results\n",
    "    nearby_transportation = pd.concat(nearby_transportation)\n",
    "\n",
    "    # Save to disk\n",
    "    nearby_transportation.to_csv(RAW_DATA + \"transportation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    nearby_transportation = pd.read_csv(RAW_DATA + \"transportation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_dataframe_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m check_dataframe_results(nearby_transportation)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_dataframe_results' is not defined"
     ]
    }
   ],
   "source": [
    "check_dataframe_results(nearby_transportation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Trustpilot WebScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trustpilot is a Danish consumer review website very popular in Denmark. It is publicly available and easy to access, but it does not provide any API integration. Therefore, we use a simple webcrawler to extract the reviews of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    dfs = []\n",
    "\n",
    "    # Reuse the gyms\n",
    "    for g in gyms:\n",
    "        df = trustpilot_crawler(key=g, verbose=False)\n",
    "\n",
    "        # Append the facility DF to main df\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Join all DFs\n",
    "    trustpilot_reviews = pd.concat(dfs)\n",
    "\n",
    "    # Save to disk\n",
    "    trustpilot_reviews.to_csv(RAW_DATA + \"trustpilot_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    trustpilot_reviews = pd.read_csv(RAW_DATA + \"trustpilot_reviews.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (2802, 7)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2802 entries, 0 to 2801\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   datetime    2802 non-null   object\n",
      " 1   name        2802 non-null   object\n",
      " 2   rating      2802 non-null   int64 \n",
      " 3   title       2802 non-null   object\n",
      " 4   review      2802 non-null   object\n",
      " 5   event_time  2802 non-null   object\n",
      " 6   enterprise  2802 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 153.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>event_time</th>\n",
       "      <th>enterprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-13T14:03:40.000Z</td>\n",
       "      <td>Jan Winther</td>\n",
       "      <td>4</td>\n",
       "      <td>Godt fitness-center</td>\n",
       "      <td>Gennemgående er jeg godt tilfreds med mit fitn...</td>\n",
       "      <td>13. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-14T13:07:20.000Z</td>\n",
       "      <td>Tina Holst</td>\n",
       "      <td>5</td>\n",
       "      <td>Syntes altid det er dejligt at komme i…</td>\n",
       "      <td>Syntes altid det er dejligt at komme i centret...</td>\n",
       "      <td>14. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-13T09:22:36.000Z</td>\n",
       "      <td>Pfændtner</td>\n",
       "      <td>5</td>\n",
       "      <td>Jeg har gået i Fitness centeret i 22år…</td>\n",
       "      <td>Jeg har gået i Fitness centeret i 22år og efte...</td>\n",
       "      <td>12. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-13T17:18:33.000Z</td>\n",
       "      <td>Gitte</td>\n",
       "      <td>5</td>\n",
       "      <td>Puregym Ikast</td>\n",
       "      <td>Puregym Ikast er et fantastisk center. Man føl...</td>\n",
       "      <td>13. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-13T10:01:35.000Z</td>\n",
       "      <td>GITTE MIKKELSEN</td>\n",
       "      <td>2</td>\n",
       "      <td>Der mangler Stram op hold</td>\n",
       "      <td>Der mangler Stram op hold (eller ligende fx Pu...</td>\n",
       "      <td>11. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime             name  rating  \\\n",
       "0  2023-11-13T14:03:40.000Z      Jan Winther       4   \n",
       "1  2023-11-14T13:07:20.000Z       Tina Holst       5   \n",
       "2  2023-11-13T09:22:36.000Z        Pfændtner       5   \n",
       "3  2023-11-13T17:18:33.000Z            Gitte       5   \n",
       "4  2023-11-13T10:01:35.000Z  GITTE MIKKELSEN       2   \n",
       "\n",
       "                                     title  \\\n",
       "0                      Godt fitness-center   \n",
       "1  Syntes altid det er dejligt at komme i…   \n",
       "2  Jeg har gået i Fitness centeret i 22år…   \n",
       "3                            Puregym Ikast   \n",
       "4                Der mangler Stram op hold   \n",
       "\n",
       "                                              review         event_time  \\\n",
       "0  Gennemgående er jeg godt tilfreds med mit fitn...  13. november 2023   \n",
       "1  Syntes altid det er dejligt at komme i centret...  14. november 2023   \n",
       "2  Jeg har gået i Fitness centeret i 22år og efte...  12. november 2023   \n",
       "3  Puregym Ikast er et fantastisk center. Man føl...  13. november 2023   \n",
       "4  Der mangler Stram op hold (eller ligende fx Pu...  11. november 2023   \n",
       "\n",
       "  enterprise  \n",
       "0    PureGym  \n",
       "1    PureGym  \n",
       "2    PureGym  \n",
       "3    PureGym  \n",
       "4    PureGym  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(trustpilot_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Københavns Kommune Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Københavns Kommune website provides an extensive list of training facilities, both indoors and outdoors. Since this is a dynamic site built on JavaScript, the traditional webcrawler approach is not suitable, and thus we will use an approach that simulates human-like interactions using Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "\n",
    "    # Create crawler instance\n",
    "    kbh_scraper = KBHFacilitiesWebScraper()\n",
    "    # Get dataframe with entries\n",
    "    kbh_facilities = kbh_scraper.get()\n",
    "\n",
    "    # Save to disk\n",
    "    kbh_facilities.to_csv(RAW_DATA + \"kbh_facilities.csv\", index=False, encoding=\"utf-16\") # Since some Danish characters don't map to utf-8, we use utf-16\n",
    "    \n",
    "\n",
    "else:\n",
    "    kbh_facilities = pd.read_csv(RAW_DATA + \"kbh_facilities.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (606, 8)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 606 entries, 0 to 605\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   type      606 non-null    object\n",
      " 1   activity  606 non-null    object\n",
      " 2   location  606 non-null    object\n",
      " 3   website   606 non-null    object\n",
      " 4   gender    606 non-null    object\n",
      " 5   age       606 non-null    object\n",
      " 6   special   606 non-null    object\n",
      " 7   address   606 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 38.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>special</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gym</td>\n",
       "      <td>Styrke- og grundtræning</td>\n",
       "      <td>SOS Motion</td>\n",
       "      <td>http://www.sosmotion.dk/</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>Sundhedshus Østerbro, Randersgade 60, 4 sal, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Kondisti</td>\n",
       "      <td>Valbyparken</td>\n",
       "      <td>None</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>Tudsemindevej, 2450 Valby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gym</td>\n",
       "      <td>Nærgymnastik</td>\n",
       "      <td>LOFskolen</td>\n",
       "      <td>https://lofskolen.dk/kurser/motion-og-sundhed/...</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>Målrettet personer der har brug for træning me...</td>\n",
       "      <td>Østerbrogade 240, 2100 København Ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ball_sports</td>\n",
       "      <td>Floorball for kvinder 65+ år</td>\n",
       "      <td>BK Skjold</td>\n",
       "      <td>https://www.bkskjold.dk/klub/boldklubben-skjol...</td>\n",
       "      <td>women</td>\n",
       "      <td>seniors</td>\n",
       "      <td>None</td>\n",
       "      <td>Nørrebrogade 208, 2200 Kbh. N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type                      activity     location  \\\n",
       "0          gym       Styrke- og grundtræning   SOS Motion   \n",
       "1     outdoors             Træningspavillion         None   \n",
       "2     outdoors                      Kondisti  Valbyparken   \n",
       "3          gym                  Nærgymnastik    LOFskolen   \n",
       "4  ball_sports  Floorball for kvinder 65+ år    BK Skjold   \n",
       "\n",
       "                                             website gender      age  \\\n",
       "0                           http://www.sosmotion.dk/   both      all   \n",
       "1                                               None   both      all   \n",
       "2                                               None   both      all   \n",
       "3  https://lofskolen.dk/kurser/motion-og-sundhed/...   both      all   \n",
       "4  https://www.bkskjold.dk/klub/boldklubben-skjol...  women  seniors   \n",
       "\n",
       "                                             special  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  Målrettet personer der har brug for træning me...   \n",
       "4                                               None   \n",
       "\n",
       "                                             address  \n",
       "0  Sundhedshus Østerbro, Randersgade 60, 4 sal, 2...  \n",
       "1                          Kvægtorvsgade, 1710 KBH V  \n",
       "2                          Tudsemindevej, 2450 Valby  \n",
       "3                 Østerbrogade 240, 2100 København Ø  \n",
       "4                      Nørrebrogade 208, 2200 Kbh. N  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(kbh_facilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Lookup reviews for KBH Facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this dataset only contains addresses, but not geolocation (latitude and longitude) or reviews for the places. We then try to collect that missing data from the Google Maps API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    # Use custom function to iterate through the facilities and retrieve coordinates and reviews for the places.\n",
    "    kbh_facilities_reviews = review_finder(gmaps, kbh_facilities)\n",
    "\n",
    "    # Save to disk\n",
    "    kbh_facilities_reviews.to_csv(RAW_DATA + \"kbh_facilities.csv\", index=False, encoding=\"utf-16\") # Since some Danish characters don't map to utf-8, we use utf-16\n",
    "\n",
    "else:\n",
    "    kbh_facilities_reviews = pd.read_csv(RAW_DATA + \"kbh_facilities_reviews.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (1841, 13)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1841 entries, 0 to 1840\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   type      1841 non-null   object \n",
      " 1   activity  1841 non-null   object \n",
      " 2   location  1756 non-null   object \n",
      " 3   website   1477 non-null   object \n",
      " 4   gender    1841 non-null   object \n",
      " 5   age       1841 non-null   object \n",
      " 6   special   250 non-null    object \n",
      " 7   address   1481 non-null   object \n",
      " 8   lat       1460 non-null   float64\n",
      " 9   lng       1460 non-null   float64\n",
      " 10  author    1841 non-null   object \n",
      " 11  review    1841 non-null   object \n",
      " 12  rating    1841 non-null   float64\n",
      "dtypes: float64(3), object(10)\n",
      "memory usage: 187.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>special</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>author</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Ximena Ramos</td>\n",
       "      <td>This was the first time that we ordered this f...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>David Olafsson</td>\n",
       "      <td>My wife and I have been coming here with our d...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Rune Madsen</td>\n",
       "      <td>Amazing new Chinese food in the area. We had M...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Richard Grieg Higginson</td>\n",
       "      <td>Nice food and staff</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Træningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kvægtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Hjalte Christiansen</td>\n",
       "      <td>We ordered lunch takeaway. But they had forgot...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type           activity location website gender  age special  \\\n",
       "0  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "1  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "2  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "3  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "4  outdoors  Træningspavillion      NaN     NaN   both  all     NaN   \n",
       "\n",
       "                     address        lat       lng                   author  \\\n",
       "0  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313             Ximena Ramos   \n",
       "1  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313           David Olafsson   \n",
       "2  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313              Rune Madsen   \n",
       "3  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313  Richard Grieg Higginson   \n",
       "4  Kvægtorvsgade, 1710 KBH V  55.669719  12.56313      Hjalte Christiansen   \n",
       "\n",
       "                                              review  rating  \n",
       "0  This was the first time that we ordered this f...     3.0  \n",
       "1  My wife and I have been coming here with our d...     5.0  \n",
       "2  Amazing new Chinese food in the area. We had M...     5.0  \n",
       "3                                Nice food and staff     4.0  \n",
       "4  We ordered lunch takeaway. But they had forgot...     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(kbh_facilities_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Join the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in constructing a dataset that includes the enterprise, rating and review text, so we need to ensure those attributes are accesible across the different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract enterprise for Google reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract enterprise for Google reviews\n",
    "_enterprises_ = []\n",
    "# Look at each row\n",
    "for ix, row in google_reviews.iterrows():\n",
    "    # If not one of the main chains, default to \"OTHER\"\n",
    "    result = \"OTHER\"\n",
    "    # Search for the enterprise in either \"type\" or \"name\" columns\n",
    "    for enterprise in gyms:\n",
    "        if (enterprise.lower() in row[\"type\"].lower()) or (enterprise.lower() in row[\"name\"].lower()):\n",
    "            result = enterprise\n",
    "            break\n",
    "    _enterprises_.append(result)\n",
    "\n",
    "google_reviews[\"enterprise\"] = _enterprises_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract enterprise for KBH Facilities reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # Extract enterprise for Google reviews\n",
    "    _enterprises_ = []\n",
    "\n",
    "    # Since some attributes are NAN, we replace them by the string \"nan\"\n",
    "    _ = kbh_facilities_reviews.fillna(\"nan\")\n",
    "\n",
    "    # Look at each row\n",
    "    for ix, row in _.iterrows():\n",
    "        # If not one of the main chains, default to \"OTHER\"\n",
    "        result = \"OTHER\"\n",
    "        # Search for the enterprise in either \"type\" or \"name\" columns\n",
    "        for enterprise in gyms:\n",
    "            _ = kbh_facilities_reviews.fillna(\"nan\")\n",
    "            if (enterprise.lower() in row[\"type\"].lower()) or (enterprise.lower() in row[\"location\"].lower()):\n",
    "                result = enterprise\n",
    "                break\n",
    "        _enterprises_.append(result)\n",
    "\n",
    "    # Add the enterprise to the dataset\n",
    "    kbh_facilities_reviews[\"enterprise\"] = _enterprises_\n",
    "\n",
    "    # Save the results to disk\n",
    "    kbh_facilities_reviews.to_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    kbh_facilities_reviews = pd.read_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Translation of Danish reviews\n",
    "Our Trustpilot dataset contains content in both English and Danish languages. We want to translate everything to english, to work with a monolingual dataset.\n",
    "To accomplish the translation task, we use a translation model from Hugging-Face: Helsinki-NLP/opus-mt-da-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # First, remove all emojis to facilitate translation\n",
    "    trustpilot_reviews[\"review\"] = trustpilot_reviews[\"review\"].apply(lambda x: remove_emojis(x))\n",
    "\n",
    "    # Use custom function to translate the Danish reviews\n",
    "    trustpilot_reviews = translate(df = trustpilot_reviews, text_colname = \"review\", translation_colname=\"translated_review\")\n",
    "else:\n",
    "    trustpilot_reviews = pd.read_csv(PROCESSED_DATA + \"trustpilot_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Translation Assesment\n",
    "We assess the quality of the model's translation by computing the WER (Word error rate) metric against human translators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_emojis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 47\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# We load the human translations and strip the emojis\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m human \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(filepath)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m human[\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m human\u001b[39m.\u001b[39;49mreview\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: remove_emojis(x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m human\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# We extact the model translations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4765\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4756\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4758\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4759\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4760\u001b[0m         func,\n\u001b[0;32m   4761\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4762\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4763\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4764\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m-> 4765\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1200\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1282\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1283\u001b[0m )\n\u001b[0;32m   1285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1286\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1291\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1292\u001b[0m     )  \u001b[39m# GH52116\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1810\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1812\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1815\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1816\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 47\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# We load the human translations and strip the emojis\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m human \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(filepath)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m human[\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m human\u001b[39m.\u001b[39mreview\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: remove_emojis(x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m human\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# We extact the model translations\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'remove_emojis' is not defined"
     ]
    }
   ],
   "source": [
    "# Translations folder\n",
    "filepath = \"../translations/human_translations.csv\"\n",
    "\n",
    "# We load the human translations and strip the emojis\n",
    "human = pd.read_csv(filepath)\n",
    "human[\"review\"] = human.review.apply(lambda x: remove_emojis(x))\n",
    "human.rename(columns={\"review\": \"text\", \"translation\": \"human\"}, inplace=True)\n",
    "\n",
    "# We extact the model translations\n",
    "machine = trustpilot_reviews[[\"review\", \"translated_review\"]]\n",
    "machine.rename(columns={\"review\": \"text\", \"translated_review\": \"machine\"}, inplace=True)\n",
    "\n",
    "# We match the translations to their human counterpart\n",
    "translations = human.merge(machine, on=\"text\", how=\"inner\")\n",
    "\n",
    "# We pass the text, human and machine translations to our custom WER class\n",
    "WER = WER(translations.text, translations.human, translations.machine)\n",
    "\n",
    "# We use our custom function to compute the average Word error rate for the whole sample\n",
    "print(f\"The WER for the translations sample is {WER.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see the top best and worst WER instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 49\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m display(WER\u001b[39m.\u001b[39mranking()\u001b[39m.\u001b[39mhead())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m display(WER\u001b[39m.\u001b[39mranking()\u001b[39m.\u001b[39mtail())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'WER' is not defined"
     ]
    }
   ],
   "source": [
    "display(WER.ranking().head())\n",
    "display(WER.ranking().tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the attributes to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match across datasets\n",
    "google_reviews = google_reviews.rename(columns={\"author_name\": \"author\", \"text\": \"review\"})\n",
    "trustpilot_reviews = trustpilot_reviews.rename(columns={\"name\": \"author\", \"translated_reviews\": \"review\"})\n",
    "\n",
    "# Columns to keep\n",
    "cols = ['enterprise', 'author', 'rating', 'review']\n",
    "\n",
    "# Keep useful columns\n",
    "google_reviews = google_reviews[cols]\n",
    "trustpilot_reviews = trustpilot_reviews[cols]\n",
    "kbh_facilities_reviews = kbh_facilities_reviews[cols]\n",
    "\n",
    "# Merge all reviews\n",
    "reviews = pd.concat([google_reviews, trustpilot_reviews, kbh_facilities_reviews]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (5003, 4)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5003 entries, 0 to 5002\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   enterprise  5003 non-null   object \n",
      " 1   author      5003 non-null   object \n",
      " 2   rating      5003 non-null   float64\n",
      " 3   review      5000 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 156.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enterprise</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>madi sharp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sweet small gym, staff are kind when you see t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Lewis Atkins</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Just a very bad gym. Staff don’t really care, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Eric</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible facilities\\nbathrooms are gross, dirt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Rune Perstrup</td>\n",
       "      <td>1.0</td>\n",
       "      <td>An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Mario Piazza</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In a huge gym there is only one hair dryer and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  enterprise         author  rating  \\\n",
       "0    PureGym     madi sharp     4.0   \n",
       "1    PureGym   Lewis Atkins     2.0   \n",
       "2    PureGym           Eric     1.0   \n",
       "3    PureGym  Rune Perstrup     1.0   \n",
       "4    PureGym   Mario Piazza     1.0   \n",
       "\n",
       "                                              review  \n",
       "0  Sweet small gym, staff are kind when you see t...  \n",
       "1  Just a very bad gym. Staff don’t really care, ...  \n",
       "2  terrible facilities\\nbathrooms are gross, dirt...  \n",
       "3  An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...  \n",
       "4  In a huge gym there is only one hair dryer and...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO: ADD DESCRIPTION OF WHAT WE WANT TO ACHIEVE WITH THIS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Annotation distribution\n",
    "To avoid introducing bias to the task, we remove all columns except for the text to annotate, and we randomly distribute the samples across annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotator\n",
       "Bogdan       600\n",
       "Chrisanna    600\n",
       "Christian    600\n",
       "Gino         600\n",
       "Veron        600\n",
       "all          100\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join both datasets\n",
    "review_text = pd.DataFrame(reviews[\"review\"])\n",
    "\n",
    "# Shuffle reviews\n",
    "review_text = review_text.sample(frac=1)\n",
    "\n",
    "# Give unique ID to reviews\n",
    "review_text[\"ID\"] = np.arange(1, len(reviews)+1)\n",
    "\n",
    "# Drop the index\n",
    "review_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Size of sample annotated by all annotators\n",
    "size = 100\n",
    "\n",
    "# Keep a list of not assigned IDs\n",
    "remaining_ids = list(review_text.ID)\n",
    "\n",
    "# Randomly select some IDs\n",
    "common_ids =np.random.choice(remaining_ids, size=size, replace=False)\n",
    "# Assign those instances to \"all\" annotators\n",
    "review_text.loc[review_text.ID.isin(common_ids), \"annotator\"] = \"all\"\n",
    "# Remove the selected IDs from the remaining not assigned IDs\n",
    "remaining_ids = [x for x in remaining_ids if x not in common_ids]\n",
    "\n",
    "# List of annotators\n",
    "annotators = [\"Bogdan\", \"Chrisanna\", \"Christian\", \"Gino\", \"Veron\"]\n",
    "\n",
    "# Size of the samples\n",
    "size = 600\n",
    "# Assign to each annotator\n",
    "for a in annotators:\n",
    "    # Randomly select some IDs\n",
    "    selected_ids = np.random.choice(remaining_ids, size=size, replace=False)\n",
    "    # Assign those instances to the specific annotator\n",
    "    review_text.loc[review_text.ID.isin(selected_ids), \"annotator\"] = a\n",
    "    # Remove the selected IDs from the remaining not assigned IDs\n",
    "    remaining_ids = [x for x in remaining_ids if x not in selected_ids]\n",
    "\n",
    "# Show number of instances per annotator\n",
    "display(review_text.groupby(\"annotator\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now distribute the samples to annotate across annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # For each annotator, create a file\n",
    "    for a in annotators:\n",
    "        # Get the annotations for the specific annotator\n",
    "        annotators_sample = reviews.loc[(reviews.annotator == a) | (reviews.annotator == \"all\"), [\"ID\", \"text\"]]\n",
    "        annotators_sample.to_csv(ANNOTATIONS_DATA + f\"annotators_samples/{a}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load the annotation responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parse_label_studio_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 61\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(ANNOTATIONS_DATA \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mannotators_results\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m# Use our custom function to parse the response file\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         df \u001b[39m=\u001b[39m parse_label_studio_file(ANNOTATIONS_DATA \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mannotators_results/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# Append to the container\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         dfs\u001b[39m.\u001b[39mappend(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'parse_label_studio_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Container for individual annotation responses datasets\n",
    "dfs = []\n",
    "\n",
    "# Look at the JSON files, parse and join\n",
    "for file in os.listdir(ANNOTATIONS_DATA + \"annotators_results\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        # Use our custom function to parse the response file\n",
    "        df = parse_label_studio_file(ANNOTATIONS_DATA + \"annotators_results/\" + file)\n",
    "        # Append to the container\n",
    "        dfs.append(df)\n",
    "\n",
    "# Join all files\n",
    "annotations = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "print(f\"A total of {annotations.shape[0]} are now joined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Calculate IAA\n",
    "To assess the reliability of the annotations we calculate Fleiss' kappa inter-annotator agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 63\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# The categories are in the columns (except the first two: \"ID\" and \"text\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m categories \u001b[39m=\u001b[39m annotations\u001b[39m.\u001b[39mcolumns[\u001b[39m2\u001b[39m:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# The possible labels are 1.0 (Positive), 0.0 (Neutral), -1.0 (Negative) or NAN (if no sentiment)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m1.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m, np\u001b[39m.\u001b[39mnan]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'annotations' is not defined"
     ]
    }
   ],
   "source": [
    "# The categories are in the columns (except the first two: \"ID\" and \"text\")\n",
    "categories = annotations.columns[2:]\n",
    "# The possible labels are 1.0 (Positive), 0.0 (Neutral), -1.0 (Negative) or NAN (if no sentiment)\n",
    "labels = [1.0, 0.0, -1.0, np.nan]\n",
    "# Select the common annotations for IAA\n",
    "common_annotations = annotations.groupby(\"ID\").filter(lambda x: len(x) == 5)\n",
    "\n",
    "IAA = fleiss_kappa(common_annotations, categories, labels=labels)\n",
    "\n",
    "print(f\"The Fleiss Kappa for IAA is {IAA:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at each category separetely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 65\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m categories:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y121sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     IAA \u001b[39m=\u001b[39m fleiss_kappa(common_annotations, [cat], labels\u001b[39m=\u001b[39mlabels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y121sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Fleiss Kappa for IAA for the \u001b[39m\u001b[39m{\u001b[39;00mcat\u001b[39m}\u001b[39;00m\u001b[39m category is \u001b[39m\u001b[39m{\u001b[39;00mIAA\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categories' is not defined"
     ]
    }
   ],
   "source": [
    "for cat in categories:\n",
    "\n",
    "    IAA = fleiss_kappa(common_annotations, [cat], labels=labels)\n",
    "\n",
    "    print(f\"The Fleiss Kappa for IAA for the {cat} category is {IAA:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Decide on a golden label\n",
    "We now decide on a golden label for the common annotations. We will use majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_annotations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 67\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Select the golden label by majority voting\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y123sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m common_annotations \u001b[39m=\u001b[39m common_annotations\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mID\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39magg(\u001b[39mlambda\u001b[39;00m x: pd\u001b[39m.\u001b[39mSeries\u001b[39m.\u001b[39mmode(x, dropna\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y123sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Join to individual annotations\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y123sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m annotations \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([common_annotations, annotations[\u001b[39m~\u001b[39mannotations\u001b[39m.\u001b[39mID\u001b[39m.\u001b[39misin(common_annotations\u001b[39m.\u001b[39mID)]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'common_annotations' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the golden label by majority voting\n",
    "common_annotations = common_annotations.groupby(\"ID\").agg(lambda x: pd.Series.mode(x, dropna=False)[0]).reset_index()\n",
    "\n",
    "# Join to individual annotations\n",
    "annotations = pd.concat([common_annotations, annotations[~annotations.ID.isin(common_annotations.ID)]])\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Auto-labeller classifier\n",
    "Train a classifier model using Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Pre-Processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 71\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Make a copy of the annotations\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m annotations\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Convert the labels into text\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df\u001b[39m.\u001b[39miloc[:,\u001b[39m2\u001b[39m:] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:,\u001b[39m2\u001b[39m:]\u001b[39m.\u001b[39mapplymap(\u001b[39mlambda\u001b[39;00m x: num_to_sent(x))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'annotations' is not defined"
     ]
    }
   ],
   "source": [
    "# Make a copy of the annotations\n",
    "df = annotations.copy()\n",
    "# Convert the labels into text\n",
    "df.iloc[:,2:] = df.iloc[:,2:].applymap(lambda x: num_to_sent(x))\n",
    "# Lemmatize\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: lemmatize_with_postag(x))\n",
    "\n",
    "# Use vectorizer to encode text as features. TfidfVectorizer takes care of lowering and tokenizing the text\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, strip_accents=\"unicode\")\n",
    "X_tfidf = vectorizer.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Training and testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 73\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y132sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scoring_metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mprecision_macro\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall_macro\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y132sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Evaluate category-wise\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y132sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m cat \u001b[39min\u001b[39;00m categories:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y132sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(cat)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y132sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Perform cross-validation\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categories' is not defined"
     ]
    }
   ],
   "source": [
    "# Choose your classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring_metrics = ['precision_macro', 'recall_macro', 'f1_macro', \"accuracy\"]\n",
    "\n",
    "# Evaluate category-wise\n",
    "for cat in categories:\n",
    "    print(cat)\n",
    "    # Perform cross-validation\n",
    "    scores = cross_validate(classifier, X_tfidf, df[cat], cv=cv, scoring=scoring_metrics, return_train_score=False, error_score=\"raise\")\n",
    "\n",
    "    # Display the results\n",
    "    print(\"Cross-Validation Scores:\")\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores.loc['mean'] = scores.mean()\n",
    "    scores = scores.round(decimals=2)\n",
    "    display(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Labelling all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lemmatize_with_postag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 75\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# We can't predict on missing text reviews\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reviews_w_NA \u001b[39m=\u001b[39m reviews[\u001b[39m~\u001b[39mreviews\u001b[39m.\u001b[39mreview\u001b[39m.\u001b[39misna()]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reviews_w_NA[\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m reviews_w_NA[\u001b[39m\"\u001b[39;49m\u001b[39mreview\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: lemmatize_with_postag(x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_tfidf \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform(reviews_w_NA\u001b[39m.\u001b[39mreview)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Choose your classifier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4765\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4756\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4758\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4759\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4760\u001b[0m         func,\n\u001b[0;32m   4761\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4762\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4763\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4764\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m-> 4765\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1201\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1200\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1201\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1281\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1275\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1276\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1281\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1282\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1283\u001b[0m )\n\u001b[0;32m   1285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1286\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1287\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReturning a DataFrame from Series.apply when the supplied function \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1288\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mreturns a Series is deprecated and will be removed in a future \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1291\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1292\u001b[0m     )  \u001b[39m# GH52116\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Veronii\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1812\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1810\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1811\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1812\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1815\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1816\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 75\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# We can't predict on missing text reviews\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m reviews_w_NA \u001b[39m=\u001b[39m reviews[\u001b[39m~\u001b[39mreviews\u001b[39m.\u001b[39mreview\u001b[39m.\u001b[39misna()]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m reviews_w_NA[\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m reviews_w_NA[\u001b[39m\"\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: lemmatize_with_postag(x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_tfidf \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform(reviews_w_NA\u001b[39m.\u001b[39mreview)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y134sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Choose your classifier\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lemmatize_with_postag' is not defined"
     ]
    }
   ],
   "source": [
    "# Lemmatize and use the vectorizer to transform text to features\n",
    "vectorizer = TfidfVectorizer(stop_words='english', strip_accents=\"unicode\")\n",
    "# We can't predict on missing text reviews\n",
    "reviews_w_NA = reviews[~reviews.review.isna()]\n",
    "reviews_w_NA[\"review\"] = reviews_w_NA[\"review\"].apply(lambda x: lemmatize_with_postag(x))\n",
    "X_tfidf = vectorizer.fit_transform(reviews_w_NA.review)\n",
    "\n",
    "# Choose your classifier\n",
    "for cat in categories:\n",
    "    # Train the classifier for a given category\n",
    "    classifier = MultinomialNB()\n",
    "    X_train = vectorizer.transform(df.text)\n",
    "    y_train = df[cat]\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on all instances of the reviews\n",
    "    y_pred = classifier.predict(X_tfidf)\n",
    "    reviews_w_NA[cat] = y_pred\n",
    "\n",
    "# Look at the final results\n",
    "reviews = pd.concat([reviews_w_NA, reviews[reviews.review.isna()]])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualizing the facilities with Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the starting point for the map\n",
    "lat = 56\n",
    "lng = 9\n",
    "\n",
    "denmark_map = folium.Map(location=[lat,lng], zoom_start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocations_google = pd.read_csv(RAW_DATA + \"google_reviews.csv\") \n",
    "geolocations_kbh = pd.read_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geolocations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 79\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y141sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# group the data by the chosen field and aggregate various columns\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y141sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grouped_data \u001b[39m=\u001b[39m geolocations\u001b[39m.\u001b[39mgroupby([\u001b[39m\"\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlng\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m})\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y141sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m grouped_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m grouped_data[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mround(\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y141sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m marker_cluster \u001b[39m=\u001b[39m MarkerCluster()\u001b[39m.\u001b[39madd_to(denmark_map)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'geolocations' is not defined"
     ]
    }
   ],
   "source": [
    "# group the data by the chosen field and aggregate various columns\n",
    "grouped_data = geolocations.groupby([\"lat\", \"lng\"]).agg({'type': 'first', 'rating': 'mean'}).reset_index()\n",
    "\n",
    "grouped_data['rating'] = grouped_data['rating'].round(1)\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(denmark_map)\n",
    "get_color_for_location = get_rating_average(grouped_data)\n",
    "\n",
    "# iterate over each row in the grouped data.\n",
    "for index, row in grouped_data.iterrows():\n",
    "    lat, lng = row['lat'], row['lng']\n",
    "    # skip rows where lat and lng is missing\n",
    "    if lat == None or lng == None:\n",
    "        continue\n",
    "    try:\n",
    "        lat_float = float(lat)\n",
    "        lng_float = float(lng)\n",
    "\n",
    "        color = get_color_for_location(lat_float, lng_float)\n",
    "        popup_content = f\"Type: {row['type']}<br> Rating: {row['rating']}\"\n",
    "\n",
    "        # add a marker to the cluster\n",
    "        marker_cluster.add_child(\n",
    "            folium.Marker(\n",
    "                location=[lat_float, lng_float],\n",
    "                popup=popup_content,\n",
    "                icon=folium.Icon(color=color, icon=\"dumbbell\", prefix='fa')\n",
    "            )\n",
    "        )\n",
    "    except ValueError:\n",
    "         continue\n",
    "\n",
    "denmark_map.add_child(marker_cluster)\n",
    "\n",
    "# denmark_map.save('../visualizations/google_reviews_map.html')\n",
    "denmark_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
