{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Meaningful title >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Maps API\n",
    "import googlemaps\n",
    "\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Custom util functions\n",
    "import sys; sys.path.append(\"./libraries/\")\n",
    "from utils import *\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reproducibility settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed\n",
    "np.random.seed = 7\n",
    "\n",
    "# Relative Paths\n",
    "RAW_DATA = \"../data/raw_data/\"\n",
    "PROCESSED_DATA = \"../data/processed_data/\"\n",
    "ANNOTATIONS_DATA = \"../annotations/\"\n",
    "\n",
    "# Flags\n",
    "collect = False # Flag to collect data or load existent raw_data\n",
    "process = False # Flag to process data or load existent processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open(\"./Google_API_key.txt\").readline()\n",
    "gmaps = googlemaps.Client(key=key)\n",
    "\n",
    "#api = None # enter API key here\n",
    "#gmaps = googlemaps.Client(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating a list of query values that relate to the dataset. We are interested in getting mostly reviews (and some other metadata) on specific fitness facilities (i.e. popular chains) from main cities in Denmark. To do this, we will compute the query list as a combination of cities and fitness chains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PureGym Copenhagen', 'PureGym Aalborg', 'PureGym Arhus', 'PureGym Odense', 'SATS Copenhagen', 'SATS Aalborg', 'SATS Arhus', 'SATS Odense', 'Vesterbronx Copenhagen', 'Vesterbronx Aalborg', 'Vesterbronx Arhus', 'Vesterbronx Odense']\n"
     ]
    }
   ],
   "source": [
    "# List of cities\n",
    "cities = ['Copenhagen', 'Aalborg', 'Arhus', 'Odense']\n",
    " \n",
    "# Popular fitness chains\n",
    "gyms = [\"PureGym\", \"SATS\", \"Vesterbronx\"]\n",
    "\n",
    "# Query list\n",
    "query_list = [g + \" \" + c for g in gyms for c in cities]\n",
    "\n",
    "print(query_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Google Maps API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Google maps API takes a single query string to search for results (similar to the User Interface searchbox). Therefore, we combine popular fitness facilities with main Danish cities as our query keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Reviews\n",
    "We start by getting the reviews for our query list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get responses for all the queries from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    # Get response for queries\n",
    "    dfs = []\n",
    "\n",
    "    # For each query in the query list\n",
    "    for query in query_list:  \n",
    "        # Get the response using our custom made querier\n",
    "        dfs.append(google_querier(gmaps, query))\n",
    "\n",
    "    google_reviews = pd.concat(dfs)\n",
    "\n",
    "    # Save to disk\n",
    "    google_reviews.to_csv(RAW_DATA + \"google_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    google_reviews = pd.read_csv(RAW_DATA + \"google_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (360, 9)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 360 entries, 0 to 359\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   place_id       360 non-null    object \n",
      " 1   type           360 non-null    object \n",
      " 2   name           360 non-null    object \n",
      " 3   lat            360 non-null    float64\n",
      " 4   lng            360 non-null    float64\n",
      " 5   author_name    360 non-null    object \n",
      " 6   rating         360 non-null    int64  \n",
      " 7   text           360 non-null    object \n",
      " 8   opening_hours  360 non-null    object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 25.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>author_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>opening_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>madi sharp</td>\n",
       "      <td>4</td>\n",
       "      <td>Sweet small gym, staff are kind when you see t...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Lewis Atkins</td>\n",
       "      <td>2</td>\n",
       "      <td>Just a very bad gym. Staff donâ€™t really care, ...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Eric</td>\n",
       "      <td>1</td>\n",
       "      <td>terrible facilities\\nbathrooms are gross, dirt...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Rune Perstrup</td>\n",
       "      <td>1</td>\n",
       "      <td>An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>PureGym Copenhagen</td>\n",
       "      <td>PureGym</td>\n",
       "      <td>55.669812</td>\n",
       "      <td>12.54739</td>\n",
       "      <td>Mario Piazza</td>\n",
       "      <td>1</td>\n",
       "      <td>In a huge gym there is only one hair dryer and...</td>\n",
       "      <td>{'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id                type     name        lat  \\\n",
       "0  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "1  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "2  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "3  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "4  ChIJh3mB6UxSUkYREbiH4JDK-7M  PureGym Copenhagen  PureGym  55.669812   \n",
       "\n",
       "        lng    author_name  rating  \\\n",
       "0  12.54739     madi sharp       4   \n",
       "1  12.54739   Lewis Atkins       2   \n",
       "2  12.54739           Eric       1   \n",
       "3  12.54739  Rune Perstrup       1   \n",
       "4  12.54739   Mario Piazza       1   \n",
       "\n",
       "                                                text  \\\n",
       "0  Sweet small gym, staff are kind when you see t...   \n",
       "1  Just a very bad gym. Staff donâ€™t really care, ...   \n",
       "2  terrible facilities\\nbathrooms are gross, dirt...   \n",
       "3  An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...   \n",
       "4  In a huge gym there is only one hair dryer and...   \n",
       "\n",
       "                                       opening_hours  \n",
       "0  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "1  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "2  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "3  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  \n",
       "4  {'Monday': '05:00AM - 12:00AM', 'Tuesday': '05...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(google_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Nearby Transportation\n",
    "We are interested in collecting the nearby transportation to the fitness centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "\n",
    "    # Radius of search in meters\n",
    "    radius = 500\n",
    "\n",
    "    # Transportation type key (similar to what one would input in Google Maps search box)\n",
    "    transportation_type = ['bus_station', 'train_station', 'transit_station'] # Avaliable transportation: only bus station, train station and transit station (which includes metro)\n",
    "\n",
    "    # Container\n",
    "    nearby_transportation = []\n",
    "\n",
    "    # We iterate through all our fitness centers, and retrieve nearby transportations\n",
    "    for ix, row in google_reviews.iterrows():\n",
    "        # Extract info from fitness center\n",
    "        place_id = row.place_id\n",
    "        location = {\"lat\": row.lat, \"lng\": row.lng}\n",
    "        # Look at nearby transportation\n",
    "        df = google_nearby(gmaps, place_id = place_id, keys = transportation_type, location = location, radius = radius)\n",
    "        # Append results\n",
    "        nearby_transportation.append(df)\n",
    "\n",
    "    # Join all results\n",
    "    nearby_transportation = pd.concat(nearby_transportation)\n",
    "\n",
    "    # Save to disk\n",
    "    nearby_transportation.to_csv(RAW_DATA + \"transportation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    nearby_transportation = pd.read_csv(RAW_DATA + \"transportation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (6195, 7)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6195 entries, 0 to 6194\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   place_id                6195 non-null   object \n",
      " 1   transport_id            6195 non-null   object \n",
      " 2   transport_name          6195 non-null   object \n",
      " 3   transport_type          6195 non-null   object \n",
      " 4   transport_lat           6195 non-null   float64\n",
      " 5   transport_lng           6195 non-null   float64\n",
      " 6   distance_gym_transport  6195 non-null   int64  \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 338.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_id</th>\n",
       "      <th>transport_id</th>\n",
       "      <th>transport_name</th>\n",
       "      <th>transport_type</th>\n",
       "      <th>transport_lat</th>\n",
       "      <th>transport_lng</th>\n",
       "      <th>distance_gym_transport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>ChIJ-y92w3VTUkYRY8NOJNuwQkQ</td>\n",
       "      <td>Kridt v/Rikke Frisk</td>\n",
       "      <td>bus_station</td>\n",
       "      <td>55.668036</td>\n",
       "      <td>12.551084</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>ChIJ76k9hJ9TUkYRRaHYcLRX3XE</td>\n",
       "      <td>Lysholdet v/Jakob Holst</td>\n",
       "      <td>bus_station</td>\n",
       "      <td>55.672786</td>\n",
       "      <td>12.547279</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>ChIJydMagp9TUkYRjfgBz2sKErQ</td>\n",
       "      <td>Ejerforeningen Sigbrits AllÃ© 3, 5 og 5a</td>\n",
       "      <td>bus_station</td>\n",
       "      <td>55.672865</td>\n",
       "      <td>12.546713</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>ChIJydMagp9TUkYRcgSv8LkczNs</td>\n",
       "      <td>Grundejerforeningen Carl Jacobsens Vej 33-41</td>\n",
       "      <td>bus_station</td>\n",
       "      <td>55.672865</td>\n",
       "      <td>12.546713</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChIJh3mB6UxSUkYREbiH4JDK-7M</td>\n",
       "      <td>ChIJl46JnZ5TUkYRnW93t25gFhQ</td>\n",
       "      <td>Optiperform v/Maja Juel-Hansen</td>\n",
       "      <td>bus_station</td>\n",
       "      <td>55.668011</td>\n",
       "      <td>12.542917</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      place_id                 transport_id  \\\n",
       "0  ChIJh3mB6UxSUkYREbiH4JDK-7M  ChIJ-y92w3VTUkYRY8NOJNuwQkQ   \n",
       "1  ChIJh3mB6UxSUkYREbiH4JDK-7M  ChIJ76k9hJ9TUkYRRaHYcLRX3XE   \n",
       "2  ChIJh3mB6UxSUkYREbiH4JDK-7M  ChIJydMagp9TUkYRjfgBz2sKErQ   \n",
       "3  ChIJh3mB6UxSUkYREbiH4JDK-7M  ChIJydMagp9TUkYRcgSv8LkczNs   \n",
       "4  ChIJh3mB6UxSUkYREbiH4JDK-7M  ChIJl46JnZ5TUkYRnW93t25gFhQ   \n",
       "\n",
       "                                 transport_name transport_type  transport_lat  \\\n",
       "0                           Kridt v/Rikke Frisk    bus_station      55.668036   \n",
       "1                       Lysholdet v/Jakob Holst    bus_station      55.672786   \n",
       "2       Ejerforeningen Sigbrits AllÃ© 3, 5 og 5a    bus_station      55.672865   \n",
       "3  Grundejerforeningen Carl Jacobsens Vej 33-41    bus_station      55.672865   \n",
       "4                Optiperform v/Maja Juel-Hansen    bus_station      55.668011   \n",
       "\n",
       "   transport_lng  distance_gym_transport  \n",
       "0      12.551084                     305  \n",
       "1      12.547279                     331  \n",
       "2      12.546713                     343  \n",
       "3      12.546713                     343  \n",
       "4      12.542917                     346  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(nearby_transportation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Trustpilot WebScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trustpilot is a Danish consumer review website very popular in Denmark. It is publicly available and easy to access, but it does not provide any API integration. Therefore, we use a simple webcrawler to extract the reviews of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    dfs = []\n",
    "\n",
    "    # Reuse the gyms\n",
    "    for g in gyms:\n",
    "        df = trustpilot_crawler(key=g, verbose=False)\n",
    "\n",
    "        # Append the facility DF to main df\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Join all DFs\n",
    "    trustpilot_reviews = pd.concat(dfs)\n",
    "\n",
    "    # Save to disk\n",
    "    trustpilot_reviews.to_csv(RAW_DATA + \"trustpilot_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    trustpilot_reviews = pd.read_csv(RAW_DATA + \"trustpilot_reviews.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (2802, 7)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2802 entries, 0 to 2801\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   datetime    2802 non-null   object\n",
      " 1   name        2802 non-null   object\n",
      " 2   rating      2802 non-null   int64 \n",
      " 3   title       2802 non-null   object\n",
      " 4   review      2802 non-null   object\n",
      " 5   event_time  2802 non-null   object\n",
      " 6   enterprise  2802 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 153.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>event_time</th>\n",
       "      <th>enterprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-13T14:03:40.000Z</td>\n",
       "      <td>Jan Winther</td>\n",
       "      <td>4</td>\n",
       "      <td>Godt fitness-center</td>\n",
       "      <td>GennemgÃ¥ende er jeg godt tilfreds med mit fitn...</td>\n",
       "      <td>13. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-14T13:07:20.000Z</td>\n",
       "      <td>Tina Holst</td>\n",
       "      <td>5</td>\n",
       "      <td>Syntes altid det er dejligt at komme iâ€¦</td>\n",
       "      <td>Syntes altid det er dejligt at komme i centret...</td>\n",
       "      <td>14. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-13T09:22:36.000Z</td>\n",
       "      <td>PfÃ¦ndtner</td>\n",
       "      <td>5</td>\n",
       "      <td>Jeg har gÃ¥et i Fitness centeret i 22Ã¥râ€¦</td>\n",
       "      <td>Jeg har gÃ¥et i Fitness centeret i 22Ã¥r og efte...</td>\n",
       "      <td>12. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-13T17:18:33.000Z</td>\n",
       "      <td>Gitte</td>\n",
       "      <td>5</td>\n",
       "      <td>Puregym Ikast</td>\n",
       "      <td>Puregym Ikast er et fantastisk center. Man fÃ¸l...</td>\n",
       "      <td>13. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-13T10:01:35.000Z</td>\n",
       "      <td>GITTE MIKKELSEN</td>\n",
       "      <td>2</td>\n",
       "      <td>Der mangler Stram op hold</td>\n",
       "      <td>Der mangler Stram op hold (eller ligende fx Pu...</td>\n",
       "      <td>11. november 2023</td>\n",
       "      <td>PureGym</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime             name  rating  \\\n",
       "0  2023-11-13T14:03:40.000Z      Jan Winther       4   \n",
       "1  2023-11-14T13:07:20.000Z       Tina Holst       5   \n",
       "2  2023-11-13T09:22:36.000Z        PfÃ¦ndtner       5   \n",
       "3  2023-11-13T17:18:33.000Z            Gitte       5   \n",
       "4  2023-11-13T10:01:35.000Z  GITTE MIKKELSEN       2   \n",
       "\n",
       "                                     title  \\\n",
       "0                      Godt fitness-center   \n",
       "1  Syntes altid det er dejligt at komme iâ€¦   \n",
       "2  Jeg har gÃ¥et i Fitness centeret i 22Ã¥râ€¦   \n",
       "3                            Puregym Ikast   \n",
       "4                Der mangler Stram op hold   \n",
       "\n",
       "                                              review         event_time  \\\n",
       "0  GennemgÃ¥ende er jeg godt tilfreds med mit fitn...  13. november 2023   \n",
       "1  Syntes altid det er dejligt at komme i centret...  14. november 2023   \n",
       "2  Jeg har gÃ¥et i Fitness centeret i 22Ã¥r og efte...  12. november 2023   \n",
       "3  Puregym Ikast er et fantastisk center. Man fÃ¸l...  13. november 2023   \n",
       "4  Der mangler Stram op hold (eller ligende fx Pu...  11. november 2023   \n",
       "\n",
       "  enterprise  \n",
       "0    PureGym  \n",
       "1    PureGym  \n",
       "2    PureGym  \n",
       "3    PureGym  \n",
       "4    PureGym  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(trustpilot_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 KÃ¸benhavns Kommune Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KÃ¸benhavns Kommune website provides an extensive list of training facilities, both indoors and outdoors. Since this is a dynamic site built on JavaScript, the traditional webcrawler approach is not suitable, and thus we will use an approach that simulates human-like interactions using Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "\n",
    "    # Create crawler instance\n",
    "    kbh_scraper = KBHFacilitiesWebScraper()\n",
    "    # Get dataframe with entries\n",
    "    kbh_facilities = kbh_scraper.get()\n",
    "\n",
    "    # Save to disk\n",
    "    kbh_facilities.to_csv(RAW_DATA + \"kbh_facilities.csv\", index=False, encoding=\"utf-16\") # Since some Danish characters don't map to utf-8, we use utf-16\n",
    "    \n",
    "\n",
    "else:\n",
    "    kbh_facilities = pd.read_csv(RAW_DATA + \"kbh_facilities.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (606, 8)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 606 entries, 0 to 605\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   type      606 non-null    object\n",
      " 1   activity  606 non-null    object\n",
      " 2   location  606 non-null    object\n",
      " 3   website   606 non-null    object\n",
      " 4   gender    606 non-null    object\n",
      " 5   age       606 non-null    object\n",
      " 6   special   606 non-null    object\n",
      " 7   address   606 non-null    object\n",
      "dtypes: object(8)\n",
      "memory usage: 38.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>special</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gym</td>\n",
       "      <td>Styrke- og grundtrÃ¦ning</td>\n",
       "      <td>SOS Motion</td>\n",
       "      <td>http://www.sosmotion.dk/</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>Sundhedshus Ã˜sterbro, Randersgade 60, 4 sal, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>TrÃ¦ningspavillion</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>KvÃ¦gtorvsgade, 1710 KBH V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>Kondisti</td>\n",
       "      <td>Valbyparken</td>\n",
       "      <td>None</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>None</td>\n",
       "      <td>Tudsemindevej, 2450 Valby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gym</td>\n",
       "      <td>NÃ¦rgymnastik</td>\n",
       "      <td>LOFskolen</td>\n",
       "      <td>https://lofskolen.dk/kurser/motion-og-sundhed/...</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>MÃ¥lrettet personer der har brug for trÃ¦ning me...</td>\n",
       "      <td>Ã˜sterbrogade 240, 2100 KÃ¸benhavn Ã˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ball_sports</td>\n",
       "      <td>Floorball for kvinder 65+ Ã¥r</td>\n",
       "      <td>BK Skjold</td>\n",
       "      <td>https://www.bkskjold.dk/klub/boldklubben-skjol...</td>\n",
       "      <td>women</td>\n",
       "      <td>seniors</td>\n",
       "      <td>None</td>\n",
       "      <td>NÃ¸rrebrogade 208, 2200 Kbh. N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          type                      activity     location  \\\n",
       "0          gym       Styrke- og grundtrÃ¦ning   SOS Motion   \n",
       "1     outdoors             TrÃ¦ningspavillion         None   \n",
       "2     outdoors                      Kondisti  Valbyparken   \n",
       "3          gym                  NÃ¦rgymnastik    LOFskolen   \n",
       "4  ball_sports  Floorball for kvinder 65+ Ã¥r    BK Skjold   \n",
       "\n",
       "                                             website gender      age  \\\n",
       "0                           http://www.sosmotion.dk/   both      all   \n",
       "1                                               None   both      all   \n",
       "2                                               None   both      all   \n",
       "3  https://lofskolen.dk/kurser/motion-og-sundhed/...   both      all   \n",
       "4  https://www.bkskjold.dk/klub/boldklubben-skjol...  women  seniors   \n",
       "\n",
       "                                             special  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  MÃ¥lrettet personer der har brug for trÃ¦ning me...   \n",
       "4                                               None   \n",
       "\n",
       "                                             address  \n",
       "0  Sundhedshus Ã˜sterbro, Randersgade 60, 4 sal, 2...  \n",
       "1                          KvÃ¦gtorvsgade, 1710 KBH V  \n",
       "2                          Tudsemindevej, 2450 Valby  \n",
       "3                 Ã˜sterbrogade 240, 2100 KÃ¸benhavn Ã˜  \n",
       "4                      NÃ¸rrebrogade 208, 2200 Kbh. N  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(kbh_facilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Lookup reviews for KBH Facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that this dataset only contains addresses, but not geolocation (latitude and longitude) or reviews for the places. We then try to collect that missing data from the Google Maps API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if collect:\n",
    "    # Use custom function to iterate through the facilities and retrieve coordinates and reviews for the places.\n",
    "    kbh_facilities_reviews = review_finder(gmaps, kbh_facilities)\n",
    "\n",
    "    # Save to disk\n",
    "    kbh_facilities_reviews.to_csv(RAW_DATA + \"kbh_facilities.csv\", index=False, encoding=\"utf-16\") # Since some Danish characters don't map to utf-8, we use utf-16\n",
    "\n",
    "else:\n",
    "    kbh_facilities_reviews = pd.read_csv(RAW_DATA + \"kbh_facilities_reviews.csv\", encoding=\"utf-16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (1841, 13)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1841 entries, 0 to 1840\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   type      1841 non-null   object \n",
      " 1   activity  1841 non-null   object \n",
      " 2   location  1756 non-null   object \n",
      " 3   website   1477 non-null   object \n",
      " 4   gender    1841 non-null   object \n",
      " 5   age       1841 non-null   object \n",
      " 6   special   250 non-null    object \n",
      " 7   address   1481 non-null   object \n",
      " 8   lat       1460 non-null   float64\n",
      " 9   lng       1460 non-null   float64\n",
      " 10  author    1841 non-null   object \n",
      " 11  review    1841 non-null   object \n",
      " 12  rating    1841 non-null   float64\n",
      "dtypes: float64(3), object(10)\n",
      "memory usage: 187.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>activity</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>special</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>author</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>TrÃ¦ningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KvÃ¦gtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Ximena Ramos</td>\n",
       "      <td>This was the first time that we ordered this f...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>TrÃ¦ningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KvÃ¦gtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>David Olafsson</td>\n",
       "      <td>My wife and I have been coming here with our d...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>TrÃ¦ningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KvÃ¦gtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Rune Madsen</td>\n",
       "      <td>Amazing new Chinese food in the area. We had M...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>TrÃ¦ningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KvÃ¦gtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Richard Grieg Higginson</td>\n",
       "      <td>Nice food and staff</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outdoors</td>\n",
       "      <td>TrÃ¦ningspavillion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "      <td>all</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KvÃ¦gtorvsgade, 1710 KBH V</td>\n",
       "      <td>55.669719</td>\n",
       "      <td>12.56313</td>\n",
       "      <td>Hjalte Christiansen</td>\n",
       "      <td>We ordered lunch takeaway. But they had forgot...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type           activity location website gender  age special  \\\n",
       "0  outdoors  TrÃ¦ningspavillion      NaN     NaN   both  all     NaN   \n",
       "1  outdoors  TrÃ¦ningspavillion      NaN     NaN   both  all     NaN   \n",
       "2  outdoors  TrÃ¦ningspavillion      NaN     NaN   both  all     NaN   \n",
       "3  outdoors  TrÃ¦ningspavillion      NaN     NaN   both  all     NaN   \n",
       "4  outdoors  TrÃ¦ningspavillion      NaN     NaN   both  all     NaN   \n",
       "\n",
       "                     address        lat       lng                   author  \\\n",
       "0  KvÃ¦gtorvsgade, 1710 KBH V  55.669719  12.56313             Ximena Ramos   \n",
       "1  KvÃ¦gtorvsgade, 1710 KBH V  55.669719  12.56313           David Olafsson   \n",
       "2  KvÃ¦gtorvsgade, 1710 KBH V  55.669719  12.56313              Rune Madsen   \n",
       "3  KvÃ¦gtorvsgade, 1710 KBH V  55.669719  12.56313  Richard Grieg Higginson   \n",
       "4  KvÃ¦gtorvsgade, 1710 KBH V  55.669719  12.56313      Hjalte Christiansen   \n",
       "\n",
       "                                              review  rating  \n",
       "0  This was the first time that we ordered this f...     3.0  \n",
       "1  My wife and I have been coming here with our d...     5.0  \n",
       "2  Amazing new Chinese food in the area. We had M...     5.0  \n",
       "3                                Nice food and staff     4.0  \n",
       "4  We ordered lunch takeaway. But they had forgot...     1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(kbh_facilities_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Join the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in constructing a dataset that includes the enterprise, rating and review text, so we need to ensure those attributes are accesible across the different data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract enterprise for Google reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract enterprise for Google reviews\n",
    "_enterprises_ = []\n",
    "# Look at each row\n",
    "for ix, row in google_reviews.iterrows():\n",
    "    # If not one of the main chains, default to \"OTHER\"\n",
    "    result = \"OTHER\"\n",
    "    # Search for the enterprise in either \"type\" or \"name\" columns\n",
    "    for enterprise in gyms:\n",
    "        if (enterprise.lower() in row[\"type\"].lower()) or (enterprise.lower() in row[\"name\"].lower()):\n",
    "            result = enterprise\n",
    "            break\n",
    "    _enterprises_.append(result)\n",
    "\n",
    "google_reviews[\"enterprise\"] = _enterprises_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract enterprise for KBH Facilities reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # Extract enterprise for Google reviews\n",
    "    _enterprises_ = []\n",
    "\n",
    "    # Since some attributes are NAN, we replace them by the string \"nan\"\n",
    "    _ = kbh_facilities_reviews.fillna(\"nan\")\n",
    "\n",
    "    # Look at each row\n",
    "    for ix, row in _.iterrows():\n",
    "        # If not one of the main chains, default to \"OTHER\"\n",
    "        result = \"OTHER\"\n",
    "        # Search for the enterprise in either \"type\" or \"name\" columns\n",
    "        for enterprise in gyms:\n",
    "            _ = kbh_facilities_reviews.fillna(\"nan\")\n",
    "            if (enterprise.lower() in row[\"type\"].lower()) or (enterprise.lower() in row[\"location\"].lower()):\n",
    "                result = enterprise\n",
    "                break\n",
    "        _enterprises_.append(result)\n",
    "\n",
    "    # Add the enterprise to the dataset\n",
    "    kbh_facilities_reviews[\"enterprise\"] = _enterprises_\n",
    "\n",
    "    # Save the results to disk\n",
    "    kbh_facilities_reviews.to_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "else:\n",
    "    kbh_facilities_reviews = pd.read_csv(PROCESSED_DATA + \"kbh_facilities_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Translation of Danish reviews\n",
    "Our Trustpilot dataset contains content in both English and Danish languages. We want to translate everything to english, to work with a monolingual dataset.\n",
    "To accomplish the translation task, we use a translation model from Hugging-Face: Helsinki-NLP/opus-mt-da-en."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # First, remove all emojis to facilitate translation\n",
    "    trustpilot_reviews[\"review\"] = trustpilot_reviews[\"review\"].apply(lambda x: remove_emojis(x))\n",
    "\n",
    "    # Use custom function to translate the Danish reviews\n",
    "    trustpilot_reviews = translate(df = trustpilot_reviews, text_colname = \"review\", translation_colname=\"translated_review\")\n",
    "else:\n",
    "    trustpilot_reviews = pd.read_csv(PROCESSED_DATA + \"trustpilot_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Translation Assesment\n",
    "We assess the quality of the model's translation by computing the WER (Word error rate) metric against human translators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The WER for the translations sample is 0.393\n"
     ]
    }
   ],
   "source": [
    "# Translations folder\n",
    "filepath = \"../translations/human_translations.csv\"\n",
    "\n",
    "# We load the human translations and strip the emojis\n",
    "human = pd.read_csv(filepath)\n",
    "human[\"review\"] = human.review.apply(lambda x: remove_emojis(x))\n",
    "human.rename(columns={\"review\": \"text\", \"translation\": \"human\"}, inplace=True)\n",
    "\n",
    "# We extact the model translations\n",
    "machine = trustpilot_reviews[[\"review\", \"translated_review\"]]\n",
    "machine.rename(columns={\"review\": \"text\", \"translated_review\": \"machine\"}, inplace=True)\n",
    "\n",
    "# We match the translations to their human counterpart\n",
    "translations = human.merge(machine, on=\"text\", how=\"inner\")\n",
    "\n",
    "# We split both human and machine translations\n",
    "references = translations.human\n",
    "predictions = translations.machine\n",
    "\n",
    "# We use our custom function to compute the average Word error rate for the whole sample\n",
    "print(f\"The WER for the translations sample is {compute_WER(references, predictions):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the attributes to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match across datasets\n",
    "google_reviews = google_reviews.rename(columns={\"author_name\": \"author\", \"text\": \"review\"})\n",
    "trustpilot_reviews = trustpilot_reviews.rename(columns={\"name\": \"author\", \"translated_reviews\": \"review\"})\n",
    "\n",
    "# Columns to keep\n",
    "cols = ['enterprise', 'author', 'rating', 'review']\n",
    "\n",
    "# Keep useful columns\n",
    "google_reviews = google_reviews[cols]\n",
    "trustpilot_reviews = trustpilot_reviews[cols]\n",
    "kbh_facilities_reviews = kbh_facilities_reviews[cols]\n",
    "\n",
    "# Merge all reviews\n",
    "reviews = pd.concat([google_reviews, trustpilot_reviews, kbh_facilities_reviews])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting dataframe has shape (5003, 4)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5003 entries, 0 to 1840\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   enterprise  5003 non-null   object \n",
      " 1   author      5003 non-null   object \n",
      " 2   rating      5003 non-null   float64\n",
      " 3   review      5000 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 195.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enterprise</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>madi sharp</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sweet small gym, staff are kind when you see t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Lewis Atkins</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Just a very bad gym. Staff donâ€™t really care, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Eric</td>\n",
       "      <td>1.0</td>\n",
       "      <td>terrible facilities\\nbathrooms are gross, dirt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Rune Perstrup</td>\n",
       "      <td>1.0</td>\n",
       "      <td>An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PureGym</td>\n",
       "      <td>Mario Piazza</td>\n",
       "      <td>1.0</td>\n",
       "      <td>In a huge gym there is only one hair dryer and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  enterprise         author  rating  \\\n",
       "0    PureGym     madi sharp     4.0   \n",
       "1    PureGym   Lewis Atkins     2.0   \n",
       "2    PureGym           Eric     1.0   \n",
       "3    PureGym  Rune Perstrup     1.0   \n",
       "4    PureGym   Mario Piazza     1.0   \n",
       "\n",
       "                                              review  \n",
       "0  Sweet small gym, staff are kind when you see t...  \n",
       "1  Just a very bad gym. Staff donâ€™t really care, ...  \n",
       "2  terrible facilities\\nbathrooms are gross, dirt...  \n",
       "3  An Unhygienic Coronavirus Petri Dish.\\n\\nI hav...  \n",
       "4  In a huge gym there is only one hair dryer and...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_dataframe_results(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO: ADD DESCRIPTION OF WHAT WE WANT TO ACHIEVE WITH THIS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Annotation distribution\n",
    "To avoid introducing bias to the task, we remove all columns except for the text to annotate, and we randomly distribute the samples across annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotator\n",
       "Bogdan       600\n",
       "Chrisanna    600\n",
       "Christian    600\n",
       "Gino         600\n",
       "Veron        600\n",
       "all          100\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join both datasets\n",
    "review_text = pd.DataFrame(reviews[\"review\"])\n",
    "\n",
    "# Shuffle reviews\n",
    "review_text = review_text.sample(frac=1)\n",
    "\n",
    "# Give unique ID to reviews\n",
    "review_text[\"ID\"] = np.arange(1, len(reviews)+1)\n",
    "\n",
    "# Drop the index\n",
    "review_text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Size of sample annotated by all annotators\n",
    "size = 100\n",
    "\n",
    "# Keep a list of not assigned IDs\n",
    "remaining_ids = list(review_text.ID)\n",
    "\n",
    "# Randomly select some IDs\n",
    "common_ids =np.random.choice(remaining_ids, size=size, replace=False)\n",
    "# Assign those instances to \"all\" annotators\n",
    "review_text.loc[review_text.ID.isin(common_ids), \"annotator\"] = \"all\"\n",
    "# Remove the selected IDs from the remaining not assigned IDs\n",
    "remaining_ids = [x for x in remaining_ids if x not in common_ids]\n",
    "\n",
    "# List of annotators\n",
    "annotators = [\"Bogdan\", \"Chrisanna\", \"Christian\", \"Gino\", \"Veron\"]\n",
    "\n",
    "# Size of the samples\n",
    "size = 600\n",
    "# Assign to each annotator\n",
    "for a in annotators:\n",
    "    # Randomly select some IDs\n",
    "    selected_ids = np.random.choice(remaining_ids, size=size, replace=False)\n",
    "    # Assign those instances to the specific annotator\n",
    "    review_text.loc[review_text.ID.isin(selected_ids), \"annotator\"] = a\n",
    "    # Remove the selected IDs from the remaining not assigned IDs\n",
    "    remaining_ids = [x for x in remaining_ids if x not in selected_ids]\n",
    "\n",
    "# Show number of instances per annotator\n",
    "display(review_text.groupby(\"annotator\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now distribute the samples to annotate across annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if process:\n",
    "    # For each annotator, create a file\n",
    "    for a in annotators:\n",
    "        # Get the annotations for the specific annotator\n",
    "        annotators_sample = reviews.loc[(reviews.annotator == a) | (reviews.annotator == \"all\"), [\"ID\", \"text\"]]\n",
    "        annotators_sample.to_csv(ANNOTATIONS_DATA + f\"annotators_samples/{a}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load the annotation responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bogdan_annotated.json\n",
      "Christian_annotations.json\n",
      "Gino_annotations.json\n",
      "sanna.json\n",
      "veron_hoxha.json\n",
      "A total of 1008 are now joined.\n"
     ]
    }
   ],
   "source": [
    "# Container for individual annotation responses datasets\n",
    "dfs = []\n",
    "\n",
    "# Look at the JSON files, parse and join\n",
    "for file in os.listdir(ANNOTATIONS_DATA + \"annotators_results\"):\n",
    "    if file.endswith(\".json\"):\n",
    "        # Use our custom function to parse the response file\n",
    "        print(file)\n",
    "        df = parse_label_studio_file(ANNOTATIONS_DATA + \"annotators_results/\" + file)\n",
    "        # Append to the container\n",
    "        dfs.append(df)\n",
    "\n",
    "# Join all files\n",
    "annotations = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "print(f\"A total of {annotations.shape[0]} are now joined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Calculate IAA\n",
    "To assess the reliability of the annotations we calculate Fleiss' kappa inter-annotator agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Veronii\\Desktop\\data-wild-west\\code\\Project_Notebook.ipynb Cell 61\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# The categories are in the columns (except the first two: \"ID\" and \"text\")\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m categories \u001b[39m=\u001b[39m annotations\u001b[39m.\u001b[39mcolumns[\u001b[39m2\u001b[39m:]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# The possible labels are 1.0 (Positive), 0.0 (Neutral), -1.0 (Negative) or NAN (if no sentiment)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Veronii/Desktop/data-wild-west/code/Project_Notebook.ipynb#Y114sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39m1.0\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m, np\u001b[39m.\u001b[39mnan]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'annotations' is not defined"
     ]
    }
   ],
   "source": [
    "# The categories are in the columns (except the first two: \"ID\" and \"text\")\n",
    "categories = annotations.columns[3:]\n",
    "# The possible labels are 1.0 (Positive), 0.0 (Neutral), -1.0 (Negative) or NAN (if no sentiment)\n",
    "labels = [1.0, 0.0, -1.0, np.nan]\n",
    "\n",
    "IAA = fleiss_kappa(annotations, categories, labels=[1.0])\n",
    "\n",
    "print(f\"The Fleiss Kappa for IAA is {IAA:.2f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
